{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grave-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add repo root to Python path\n",
    "repo_root = os.path.abspath(\"..\")  # parent folder of notebooks\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "from statsbombpy import sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-motivation",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_ids = [72, 53, 53, 43, 55, 55]\n",
    "season_ids = [107, 315, 106, 106, 282, 43]\n",
    "\n",
    "def get_match_overview(competition_ids, season_ids, requires_360=False):\n",
    "    \"\"\"\n",
    "    Returns a filtered overview of matches for multiple competition/season pairs.\n",
    "    \n",
    "    Parameters:\n",
    "        competition_ids (int or list): ID(s) of the competition(s)\n",
    "        season_ids (int or list): ID(s) of the season(s)\n",
    "        requires_360 (bool): If True, only return matches with 360 data\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined and filtered overview dataframe\n",
    "    \"\"\"\n",
    "    # Convert single integers to lists to keep the logic unified\n",
    "    if isinstance(competition_ids, int):\n",
    "        competition_ids = [competition_ids]\n",
    "    if isinstance(season_ids, int):\n",
    "        season_ids = [season_ids]\n",
    "        \n",
    "    if len(competition_ids) != len(season_ids):\n",
    "        raise ValueError(\"The number of competition_ids must match the number of season_ids.\")\n",
    "\n",
    "    all_matches = []\n",
    "\n",
    "    # Loop through each pair\n",
    "    for comp_id, seas_id in zip(competition_ids, season_ids):\n",
    "        try:\n",
    "            df = sb.matches(competition_id=comp_id, season_id=seas_id)\n",
    "            all_matches.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not fetch matches for Comp {comp_id}, Season {seas_id}: {e}\")\n",
    "\n",
    "    if not all_matches:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Combine all fetched data\n",
    "    overview_df = pd.concat(all_matches, ignore_index=True)\n",
    "    \n",
    "    # Track 360 availability\n",
    "    overview_df['available_360'] = overview_df['match_status_360'].notna()\n",
    "\n",
    "    # --- Apply filters ---\n",
    "    if requires_360:\n",
    "        before_count = len(overview_df)\n",
    "        overview_df = overview_df[overview_df['available_360'] == True]\n",
    "        print(f\"Dropped {before_count - len(overview_df)} matches without 360 data\")\n",
    "\n",
    "    return overview_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "living-price",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 matches without 360 data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "full_overview_df = get_match_overview(competition_ids, season_ids, requires_360=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adolescent-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_overview_df = full_overview_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsbombpy import sb\n",
    "\n",
    "def download_sb_data(overview_df, download_360=True):\n",
    "    \"\"\"\n",
    "    Download StatsBomb event and 360 data for a list of matches.\n",
    "\n",
    "    Parameters:\n",
    "        overview_df (pd.DataFrame): Filtered matches overview with 'match_id'\n",
    "        download_360 (bool): If True, download SB360 frame data; else only event data\n",
    "\n",
    "    Returns:\n",
    "        events_data (list of pd.DataFrame): List of event DataFrames per match\n",
    "        frames_360_data (list of pd.DataFrame): List of SB360 frame DataFrames per match\n",
    "    \"\"\"\n",
    "    events_data = []\n",
    "    frames_360_data = []\n",
    "\n",
    "    for match_id in overview_df['match_id']:\n",
    "        # --- Download event data ---\n",
    "        try:\n",
    "            event_df = sb.events(match_id=match_id)\n",
    "            events_data.append(event_df)\n",
    "            print(f\"Downloaded events for match {match_id} ({len(event_df)} rows)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download events for match {match_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- Download 360 data if requested ---\n",
    "        if download_360:\n",
    "            try:\n",
    "                frame_df = sb.frames(match_id=match_id)\n",
    "                if 'visible_area' in frame_df.columns:\n",
    "                    frame_df = frame_df.drop(columns=['visible_area'])\n",
    "                frames_360_data.append(frame_df)\n",
    "                print(f\"Downloaded 360 frames for match {match_id} ({len(frame_df)} rows)\")\n",
    "            except Exception as e:\n",
    "                print(f\"No 360 data for match {match_id}: {e}\")\n",
    "                \n",
    "    # Store Events Dataframe\n",
    "    df_events = pd.concat(events_data, ignore_index=True)\n",
    "    print(\"starting saving event\")\n",
    "    df_events.to_parquet('data/events_data.parquet', engine=\"fastparquet\")\n",
    "    print(\"done\")\n",
    "    df_events = None\n",
    "\n",
    "    # Store 360 Dataframe\n",
    "    df_360 = pd.concat(frames_360_data, ignore_index=True)\n",
    "    print(\"starting saving 360\")\n",
    "    df_360.to_parquet('data/360_data.parquet', engine=\"fastparquet\")\n",
    "    print(\"done\")\n",
    "    df_360 = None\n",
    "\n",
    "    return events_data, frames_360_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sustained-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsbombpy import sb\n",
    "import os\n",
    "from tqdm import tqdm # Import tqdm\n",
    "\n",
    "def download_sb_data(overview_df, download_360=True):\n",
    "    \"\"\"\n",
    "    Download StatsBomb event and 360 data with a progress bar.\n",
    "    \"\"\"\n",
    "    events_list = []\n",
    "    frames_360_list = []\n",
    "    \n",
    "    # Initialize the progress bar based on the number of matches\n",
    "    match_ids = overview_df['match_id'].unique()\n",
    "    \n",
    "    print(f\"Starting download for {len(match_ids)} matches...\")\n",
    "    \n",
    "    for match_id in tqdm(match_ids, desc=\"Downloading SB Data\", unit=\"match\"):\n",
    "        # --- Download event data ---\n",
    "        try:\n",
    "            event_df = sb.events(match_id=match_id)\n",
    "            event_df['match_id'] = match_id\n",
    "            events_list.append(event_df)\n",
    "        except Exception as e:\n",
    "            # We use tqdm.write so the print doesn't break the progress bar\n",
    "            tqdm.write(f\"Failed to download events for match {match_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- Download 360 data if requested ---\n",
    "        if download_360:\n",
    "            try:\n",
    "                frame_df = sb.frames(match_id=match_id)\n",
    "                if 'visible_area' in frame_df.columns:\n",
    "                    frame_df = frame_df.drop(columns=['visible_area'])\n",
    "                \n",
    "                frame_df['match_id'] = match_id\n",
    "                frames_360_list.append(frame_df)\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"No 360 data for match {match_id}\")\n",
    "\n",
    "    # --- SAVE DATA OUTSIDE THE LOOP ---\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    if events_list:\n",
    "        print(\"\\nConcatenating and saving events...\")\n",
    "        df_events = pd.concat(events_list, ignore_index=True)\n",
    "        df_events.to_parquet('data/events_data.parquet', engine=\"fastparquet\")\n",
    "        \n",
    "    if frames_360_list:\n",
    "        print(\"Concatenating and saving 360...\")\n",
    "        df_360 = pd.concat(frames_360_list, ignore_index=True)\n",
    "        df_360.to_parquet('data/sb360_data.parquet', engine=\"fastparquet\")\n",
    "\n",
    "    print(\"Pipeline Complete.\")\n",
    "    return events_list, frames_360_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "visible-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading SB Data:   0%|          | 0/5 [00:00<?, ?match/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for 5 matches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "Downloading SB Data:  20%|██        | 1/5 [00:01<00:06,  1.64s/match]/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "Downloading SB Data:  40%|████      | 2/5 [00:03<00:05,  1.68s/match]/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "Downloading SB Data:  60%|██████    | 3/5 [00:05<00:03,  1.69s/match]/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "Downloading SB Data:  80%|████████  | 4/5 [00:06<00:01,  1.65s/match]/opt/conda/lib/python3.8/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n",
      "Downloading SB Data: 100%|██████████| 5/5 [00:08<00:00,  1.77s/match]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenating and saving events...\n",
      "Concatenating and saving 360...\n",
      "Pipeline Complete.\n"
     ]
    }
   ],
   "source": [
    "data_events, data_360 = download_sb_data(full_overview_df, download_360=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Events Dataframe\n",
    "df_events = pd.concat(data_events, ignore_index=True)\n",
    "print(\"starting saving event\")\n",
    "df_events.to_parquet('events_data.parquet', engine=\"fastparquet\")\n",
    "print(\"done\")\n",
    "df_events = None\n",
    "\n",
    "# Store 360 Dataframe\n",
    "df_360 = pd.concat(data_360, ignore_index=True)\n",
    "print(\"starting saving 360\")\n",
    "df_360.to_parquet('360_data.parquet', engine=\"fastparquet\")\n",
    "print(\"done\")\n",
    "df_360 = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_events = pd.read_parquet(\"events_data.parquet\", engine=\"fastparquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_360 = pd.read_parquet(\"360_data.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_360.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_360 = sb.frames(match_id=3788747 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
