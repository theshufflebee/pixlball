{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convenient-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Absolute path to repo root (adjust if necessary)\n",
    "repo_root = \"/files/pixlball\"\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root) \n",
    "\n",
    "# --- 2. Project Module Imports ---\n",
    "# Import all project modules using clean names\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.evaluate as evaluate\n",
    "import src.data as data\n",
    "import src.losses as losses\n",
    "import src.model as model\n",
    "import src.utils as utils\n",
    "\n",
    "# --- 3. Module Reloading (CRITICAL for Notebook Development) ---\n",
    "# Reload dependencies in order: Config/Utils -> Data/Losses/Model -> Train/Dataset/Evaluate\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(model)\n",
    "importlib.reload(losses) \n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "# --- 4. Direct Imports (For clean code in subsequent cells) ---\n",
    "# Import essential classes and functions needed for the pipeline steps\n",
    "\n",
    "# Configuration\n",
    "from src.config import DEVICE \n",
    "\n",
    "# Data/Dataset Classes\n",
    "from src.dataset import PitchDatasetMultiTask, TemporalPitchDataset, ContextPitchDatasetMultiTask, FusionPitchDataset\n",
    "\n",
    "# Training Functions\n",
    "from src.train import train_model_base_threat, train_model_context_threat\n",
    "\n",
    "# Evaluation/Helpers\n",
    "from src.evaluate import evaluate_model_base_threat, evaluate_model_context_threat\n",
    "from src.losses import get_model_criteria, FocalLossThreat\n",
    "from src.model import TinyCNN_MultiTask_Threat\n",
    "from src.utils import get_sequence_lengths\n",
    "\n",
    "# --- Final Check ---\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improving-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tamil-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462 events.\n"
     ]
    }
   ],
   "source": [
    "admin_events = [\n",
    "        'Starting XI', 'Half Start', 'Half End', 'Player On', 'Player Off',\n",
    "        'Substitution', 'Tactical Shift', 'Referee Ball-Drop', 'Injury Stoppage',\n",
    "        'Bad Behaviour', 'Shield', 'Goal Keeper'\n",
    "    ]\n",
    "\n",
    "cleaned_df = data.drop_events(data_events, rows_to_drop=admin_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "independent-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of each outcome nn_target\n",
      "Keep Possession    70920\n",
      "Lose Possession    27465\n",
      "Shot                4764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "columns_to_drop = ['clearance_body_part',\n",
    "                   'clearance_head',\n",
    "                   'clearance_left_foot',\n",
    "                   'clearance_other',\n",
    "                   'clearance_right_foot',\n",
    "                   'shot_technique',\n",
    "                   'substitution_replacement_id',\n",
    "                   'substitution_replacement',\n",
    "                   'substitution_outcome',\n",
    "                   'shot_saved_off_target',\n",
    "                   'pass_miscommunication',\n",
    "                   'goalkeeper_shot_saved_off_target',\n",
    "                   'goalkeeper_punched_out',\n",
    "                   'shot_first_time',\n",
    "                   'shot_first_time',\n",
    "                   'shot_body_part',\n",
    "                   'related_events',\n",
    "                   'pass_shot_assist', \n",
    "                   'pass_straight', \n",
    "                   'pass_switch', \n",
    "                   'pass_technique', \n",
    "                   'pass_through_ball',\n",
    "                   'goalkeeper_body_part',\n",
    "                   'goalkeeper_end_location', \n",
    "                   'goalkeeper_outcome', \n",
    "                   'goalkeeper_position', \n",
    "                   'goalkeeper_technique', \n",
    "                   'goalkeeper_type', \n",
    "                   'goalkeeper_penalty_saved_to_post', \n",
    "                   'goalkeeper_shot_saved_to_post', \n",
    "                   'goalkeeper_lost_out', \n",
    "                   'goalkeeper_Clear', \n",
    "                   'goalkeeper_In Play Safe',\n",
    "                   'shot_key_pass_id',\n",
    "                   'shot_one_on_one',\n",
    "                   'shot_end_location',\n",
    "                   'shot_type',\n",
    "                   'pass_angle',\n",
    "                   'pass_body_part',\n",
    "                   'pass_type',\n",
    "                   'pass_length',\n",
    "                   'pass_outswinging',\n",
    "                   'pass_inswinging',\n",
    "                   'pass_cross', \n",
    "                   'pass_cut_back', \n",
    "                   'pass_deflected', \n",
    "                   'pass_goal_assist', \n",
    "                   'pass_recipient', \n",
    "                   'pass_recipient_id', \n",
    "                   'pass_assisted_shot_id', \n",
    "                   'pass_no_touch', \n",
    "                   'pass_end_location', \n",
    "                   'pass_aerial_won',\n",
    "                   'pass_height',\n",
    "                   'substitution_outcome_id',\n",
    "                   'tactics',\n",
    "                   'block_deflection',\n",
    "                   'dribble_no_touch',\n",
    "                   'shot_open_goal', \n",
    "                   'shot_saved_to_post',\n",
    "                   'shot_redirect', \n",
    "                   'shot_follows_dribble',\n",
    "                   'period',\n",
    "                   'injury_stoppage_in_chanin',\n",
    "                   'block_save_block',\n",
    "                   'ball recovery_offensive',\n",
    "\n",
    "\n",
    "                   ]\n",
    "cleaned_df = data.drop_columns(cleaned_df, columns_to_drop)\n",
    "\n",
    "# add lookahead outcome\n",
    "df_with_targets = data.assign_lookahead_outcomes(cleaned_df, lookahead=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-marble",
   "metadata": {},
   "source": [
    "# Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latter-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-polymer",
   "metadata": {},
   "source": [
    "# Finalize NN Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "academic-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-musician",
   "metadata": {},
   "source": [
    "# Neural Network final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alone-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  \\\n",
      "0  8b621ae4-ea81-415c-af41-9669db9bdd93   \n",
      "1  4706efbe-767c-45aa-9351-09528a77d135   \n",
      "2  084b9a88-4efa-4947-b94d-b89face472be   \n",
      "3  27fa7d4d-d637-4487-98e2-5c078ad600c7   \n",
      "4  764d437f-f799-4489-a38f-69fbb219a6fa   \n",
      "\n",
      "                                          ball_layer  \\\n",
      "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "\n",
      "                                     teammates_layer  \\\n",
      "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
      "\n",
      "                                     opponents_layer        nn_target  \\\n",
      "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  Keep Possession   \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  Keep Possession   \n",
      "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  Keep Possession   \n",
      "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  Keep Possession   \n",
      "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  Keep Possession   \n",
      "\n",
      "   goal_flag  match_id  possession  under_pressure  counterpress  \\\n",
      "0          0   4020846           2             0.0           0.0   \n",
      "1          0   4020846           2             0.0           0.0   \n",
      "2          0   4020846           2             1.0           0.0   \n",
      "3          0   4020846           2             1.0           0.0   \n",
      "4          0   4020846           2             0.0           0.0   \n",
      "\n",
      "   dribble_nutmeg  nn_target_int  \n",
      "0             0.0              0  \n",
      "1             0.0              0  \n",
      "2             0.0              0  \n",
      "3             0.0              0  \n",
      "4             0.0              0  \n"
     ]
    }
   ],
   "source": [
    "context_cols = [\n",
    "    'under_pressure', \n",
    "    'counterpress', \n",
    "    'dribble_nutmeg'\n",
    "]\n",
    "\n",
    "# Impute NaN values with 0.0 (float)\n",
    "# This assumes NaN means the event was NOT under pressure, NOT a counterpress, etc.\n",
    "nn_dataset[context_cols] = nn_dataset[context_cols].fillna(0.0)\n",
    "\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "\n",
    "\n",
    "# Add context Columns\n",
    "\n",
    "FINAL_CONTEXTUAL_FEATURES = [\n",
    "    'under_pressure', \n",
    "    'counterpress', \n",
    "    'dribble_nutmeg'\n",
    "]\n",
    "\n",
    "context_df = nn_dataset[FINAL_CONTEXTUAL_FEATURES].copy().fillna(0.0) \n",
    "\n",
    "\n",
    "\n",
    "# Check\n",
    "print(nn_dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-strand",
   "metadata": {},
   "source": [
    "# The Goal Multi Task CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crucial-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Positive Weight (0/1 ratio): 3.00\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# 1. Define input columns & targets\n",
    "# ------------------------------------\n",
    "# This assumes nn_dataset is already loaded and processed in previous cells.\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Ensure labels are in the correct format\n",
    "event_targets = nn_dataset['nn_target_int'].values   # 0=keep, 1=lose, 2=shot (int)\n",
    "# CRITICAL: Goal flags must be float for BCEWithLogitsLoss\n",
    "goal_flags = nn_dataset['goal_flag'].values.astype(np.float32) \n",
    "\n",
    "# ------------------------------------\n",
    "# 3. Compute class weights and positive weight\n",
    "# ------------------------------------\n",
    "\n",
    "# A. Event Weights (Multi-Class) - For CrossEntropyLoss\n",
    "event_counts = Counter(event_targets)\n",
    "total_events = len(event_targets)\n",
    "\n",
    "# Using inverse frequency: total / count\n",
    "class_weights_event = torch.tensor(\n",
    "    [total_events / event_counts.get(c, 1) for c in range(len(event_counts))],\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "# B. Goal Positive Weight (Binary) - For BCEWithLogitsLoss\n",
    "goal_counts = Counter(goal_flags)\n",
    "\n",
    "STABLE_GOAL_POS_WEIGHT = 3.0\n",
    "goal_pos_weight = torch.tensor(STABLE_GOAL_POS_WEIGHT, dtype=torch.float32).to(config.DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-string",
   "metadata": {},
   "source": [
    "# Preparing the Context CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apparent-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 72117\n",
      "Total validation samples: 18030\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "VALIDATION_SIZE = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# --- 1. Define ALL inputs and targets ---\n",
    "# Input 1: The Grid Layers (X_features)\n",
    "X_features = nn_dataset[layer_columns].reset_index(drop=True)\n",
    "\n",
    "# Input 2: The Contextual 1D Features (X_context)\n",
    "# CRITICAL: Ensure this DataFrame is aligned with X_features\n",
    "X_context = context_df.reset_index(drop=True)\n",
    "\n",
    "# Targets\n",
    "event_targets = nn_dataset['nn_target_int'].values\n",
    "goal_flags = nn_dataset['goal_flag'].values.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# CRITICAL: Assign the 8 returned arrays/DataFrames to 8 descriptive variables\n",
    "(\n",
    "    X_feat_train,      # 1. Grid Layers (Train)\n",
    "    X_feat_val,        # 2. Grid Layers (Validation)\n",
    "    X_ctx_train,       # 3. Context Features (Train)\n",
    "    X_ctx_val,         # 4. Context Features (Validation)\n",
    "    y_event_train,     # 5. Event Targets (Train)\n",
    "    y_event_val,       # 6. Event Targets (Validation)\n",
    "    y_goal_train,      # 7. Goal Targets (Train)\n",
    "    y_goal_val         # 8. Goal Targets (Validation)\n",
    ") = train_test_split(\n",
    "    X_features,        # Input 1\n",
    "    X_context,         # Input 2 (NEW)\n",
    "    event_targets,     # Input 3\n",
    "    goal_flags,        # Input 4\n",
    "    test_size=VALIDATION_SIZE, \n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=event_targets # Stratify only on the multi-class target\n",
    ")\n",
    "\n",
    "# --- 3. Instantiate the two Contextual Dataset objects ---\n",
    "\n",
    "# Training Dataset (uses four 'train' splits)\n",
    "train_dataset_context = ContextPitchDatasetMultiTask(\n",
    "    nn_layers_df=X_feat_train,          # Grid Layers (Train)\n",
    "    event_targets=y_event_train,        # Event Targets (Train)\n",
    "    goal_flags=y_goal_train,            # Goal Targets (Train)\n",
    "    contextual_features_df=X_ctx_train  # Context Features (Train)\n",
    ")\n",
    "\n",
    "# Validation Dataset (uses four 'val' splits)\n",
    "validation_dataset_context = ContextPitchDatasetMultiTask(\n",
    "    nn_layers_df=X_feat_val,            # Grid Layers (Validation)\n",
    "    event_targets=y_event_val,          # Event Targets (Validation)\n",
    "    goal_flags=y_goal_val,              # Goal Targets (Validation)\n",
    "    contextual_features_df=X_ctx_val    # Context Features (Validation)\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_context)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "knowing-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context CNN Epoch 1:   0%|          | 0/2254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for Contextual CNN Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context CNN Epoch 1: 100%|██████████| 2254/2254 [00:10<00:00, 213.82it/s, event_loss=1.87, loss=4.41, shot_loss=1.69]  \n",
      "Context CNN Epoch 2: 100%|██████████| 2254/2254 [00:09<00:00, 226.28it/s, event_loss=3.92, loss=5.87, shot_loss=1.3]   \n",
      "Context CNN Epoch 3: 100%|██████████| 2254/2254 [00:10<00:00, 223.12it/s, event_loss=1.2, loss=1.2, shot_loss=0]       \n",
      "Context CNN Epoch 4: 100%|██████████| 2254/2254 [00:10<00:00, 215.20it/s, event_loss=1.57, loss=1.57, shot_loss=0]      \n",
      "Context CNN Epoch 5: 100%|██████████| 2254/2254 [00:10<00:00, 219.74it/s, event_loss=1.23, loss=1.63, shot_loss=0.266]  \n",
      "Context CNN Epoch 6: 100%|██████████| 2254/2254 [00:10<00:00, 210.07it/s, event_loss=1.79, loss=1.97, shot_loss=0.122]   \n",
      "Context CNN Epoch 7: 100%|██████████| 2254/2254 [00:10<00:00, 211.53it/s, event_loss=1.75, loss=1.78, shot_loss=0.0156]  \n",
      "Context CNN Epoch 8: 100%|██████████| 2254/2254 [00:10<00:00, 224.72it/s, event_loss=1.28, loss=1.28, shot_loss=0]       \n",
      "Context CNN Epoch 9: 100%|██████████| 2254/2254 [00:10<00:00, 221.43it/s, event_loss=1, loss=1, shot_loss=0]             \n",
      "Context CNN Epoch 10: 100%|██████████| 2254/2254 [00:10<00:00, 215.22it/s, event_loss=5.84, loss=6.1, shot_loss=0.176]      \n",
      "Context CNN Epoch 11: 100%|██████████| 2254/2254 [00:10<00:00, 219.69it/s, event_loss=5.17, loss=5.68, shot_loss=0.345]    \n",
      "Context CNN Epoch 12: 100%|██████████| 2254/2254 [00:10<00:00, 219.61it/s, event_loss=0.881, loss=0.881, shot_loss=0]       \n",
      "Context CNN Epoch 13: 100%|██████████| 2254/2254 [00:09<00:00, 226.98it/s, event_loss=1.62, loss=1.68, shot_loss=0.0359]    \n",
      "Context CNN Epoch 14: 100%|██████████| 2254/2254 [00:09<00:00, 227.12it/s, event_loss=2.07, loss=2.08, shot_loss=0.00122]   \n",
      "Context CNN Epoch 15: 100%|██████████| 2254/2254 [00:10<00:00, 217.28it/s, event_loss=0.999, loss=3.74, shot_loss=1.83]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contextual CNN Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming event_class_weights and goal_pos_weight are defined from previous cells\n",
    "NUM_CONTEXT_FEATURES = 3 \n",
    "\n",
    "print(\"Starting training for Contextual CNN Baseline...\")\n",
    "\n",
    "# Modified the Function in Loss to take correct loss function -> needs to be changed for baseline model again\n",
    "\n",
    "context_baseline_model = train_model_context_threat(\n",
    "    dataset=train_dataset_context, \n",
    "    event_class_weights=class_weights_event, # Use your calculated weights\n",
    "    goal_pos_weight=goal_pos_weight,         # Use your calculated pos_weight\n",
    "    num_context_features=NUM_CONTEXT_FEATURES\n",
    ")\n",
    "\n",
    "print(\"\\nContextual CNN Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "trying-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Contextual CNN Model...\n",
      "\n",
      "--- Event Outcome Metrics ---\n",
      "Event Accuracy: 0.5253466444814199\n",
      "Event Balanced Accuracy: 0.6189850992521696\n",
      "Event Confusion Matrix:\n",
      " [[6140 4751 1597]\n",
      " [1297 2622  738]\n",
      " [  68  107  710]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.49      0.61     12488\n",
      "           1       0.35      0.56      0.43      4657\n",
      "           2       0.23      0.80      0.36       885\n",
      "\n",
      "    accuracy                           0.53     18030\n",
      "   macro avg       0.47      0.62      0.47     18030\n",
      "weighted avg       0.67      0.53      0.55     18030\n",
      "\n",
      "\n",
      "--- Goal Prediction (xG) Metrics ---\n",
      "Goal Accuracy: 0.8598870056497175\n",
      "Goal Balanced Accuracy: 0.776158925214361\n",
      "Goal AUC-ROC Score: 0.8352515016736209\n",
      "Goal Confusion Matrix:\n",
      " [[686  86]\n",
      " [ 38  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.89      0.92       772\n",
      "         1.0       0.47      0.66      0.55       113\n",
      "\n",
      "    accuracy                           0.86       885\n",
      "   macro avg       0.71      0.78      0.73       885\n",
      "weighted avg       0.89      0.86      0.87       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming evaluate_model_context is imported and available\n",
    "\n",
    "print(\"\\nEvaluating Contextual CNN Model...\")\n",
    "\n",
    "metrics = evaluate_model_context_threat(\n",
    "    model=context_baseline_model, \n",
    "    dataset=validation_dataset_context # Evaluate on the contextual dataset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Assuming metrics contains the result from evaluate_model_context_threat\n",
    "\n",
    "event_probs = metrics['event_probs']\n",
    "\n",
    "print(\"P(Keep) | P(Lose) | P(Shot)\")\n",
    "print(\"-------------------------------\")\n",
    "print(event_probs[:5])\n",
    "\n",
    "# You can look at the average predicted probability for the Shot class across all events:\n",
    "avg_p_shot = np.mean(event_probs[:, 2])\n",
    "print(f\"\\nAverage Predicted P(Shot) across all events: {avg_p_shot:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Assuming metrics contains the result from evaluate_model_context_threat\n",
    "\n",
    "print(\"--- Goal Prediction Probabilities (xG) Analysis ---\")\n",
    "\n",
    "goal_probs = metrics['goal_probs']\n",
    "goal_labels = metrics['goal_labels'] # Actual outcome (0=No Goal, 1=Goal)\n",
    "\n",
    "print(f\"Number of Shots Evaluated: {len(goal_probs)}\")\n",
    "\n",
    "# 1. Total xG vs. Actual Goals\n",
    "total_predicted_xg = np.sum(goal_probs)\n",
    "total_true_goals = np.sum(goal_labels)\n",
    "avg_xg_per_shot = np.mean(goal_probs)\n",
    "\n",
    "print(f\"\\nTotal Predicted xG: {total_predicted_xg:.2f}\")\n",
    "print(f\"Total True Goals Scored: {total_true_goals:.2f}\")\n",
    "print(f\"Average Predicted xG per Shot: {avg_xg_per_shot:.4f}\")\n",
    "\n",
    "# 2. Calibration Check (Optional but helpful)\n",
    "# Compare the average predicted xG for shots that were goals vs. shots that were misses.\n",
    "\n",
    "# Create a DataFrame for easy slicing\n",
    "xg_df = pd.DataFrame({'xg': goal_probs, 'goal': goal_labels})\n",
    "\n",
    "avg_xg_goal = xg_df[xg_df['goal'] == 1]['xg'].mean()\n",
    "avg_xg_miss = xg_df[xg_df['goal'] == 0]['xg'].mean()\n",
    "\n",
    "print(\"\\n-- Calibration Check --\")\n",
    "print(f\"Average xG for True Goals (should be high): {avg_xg_goal:.4f}\")\n",
    "print(f\"Average xG for Missed Shots (should be low): {avg_xg_miss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
