{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facial-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Absolute path to repo root (adjust if necessary)\n",
    "repo_root = \"/files/pixlball\"\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root) \n",
    "\n",
    "# --- 2. Project Module Imports ---\n",
    "# Import all project modules using clean names\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.evaluate as evaluate\n",
    "import src.data as data\n",
    "import src.losses as losses\n",
    "import src.model as model\n",
    "import src.utils as utils\n",
    "\n",
    "# --- 3. Module Reloading (CRITICAL for Notebook Development) ---\n",
    "# Reload dependencies in order: Config/Utils -> Data/Losses/Model -> Train/Dataset/Evaluate\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(model)\n",
    "importlib.reload(losses) \n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "# --- 4. Direct Imports (For clean code in subsequent cells) ---\n",
    "# Import essential classes and functions needed for the pipeline steps\n",
    "\n",
    "# Configuration\n",
    "from src.config import DEVICE \n",
    "\n",
    "# Data/Dataset Classes\n",
    "from src.dataset import PitchDatasetMultiTask, TemporalPitchDataset, ContextPitchDatasetMultiTask, FusionPitchDataset\n",
    "\n",
    "# Training Functions\n",
    "from src.train import train_model_base_threat\n",
    "\n",
    "# Evaluation/Helpers\n",
    "from src.evaluate import evaluate_model_base_threat\n",
    "from src.losses import get_model_criteria\n",
    "from src.model import TinyCNN_MultiTask_Threat\n",
    "from src.utils import get_sequence_lengths\n",
    "\n",
    "# --- Final Check ---\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intended-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understood-emission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278 events.\n"
     ]
    }
   ],
   "source": [
    "admin_events = [\n",
    "        'Starting XI', 'Half Start', 'Half End', 'Player On', 'Player Off',\n",
    "        'Substitution', 'Tactical Shift', 'Referee Ball-Drop', 'Injury Stoppage',\n",
    "        'Bad Behaviour', 'Shield'\n",
    "    ]\n",
    "\n",
    "cleaned_df = data.drop_events(data_events, rows_to_drop=admin_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "taken-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of each outcome nn_target\n",
      "Keep Possession    71251\n",
      "Lose Possession    28252\n",
      "Shot                4830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "columns_to_drop = ['clearance_body_part',\n",
    "                   'clearance_head',\n",
    "                   'clearance_left_foot',\n",
    "                   'clearance_other',\n",
    "                   'clearance_right_foot',\n",
    "                   'shot_technique',\n",
    "                   'substitution_replacement_id',\n",
    "                   'substitution_replacement',\n",
    "                   'substitution_outcome',\n",
    "                   'shot_saved_off_target',\n",
    "                   'pass_miscommunication',\n",
    "                   'goalkeeper_shot_saved_off_target',\n",
    "                   'goalkeeper_punched_out',\n",
    "                   'shot_first_time',\n",
    "                   'shot_first_time',\n",
    "                   'shot_body_part',\n",
    "                   'related_events',\n",
    "                   'pass_shot_assist', \n",
    "                   'pass_straight', \n",
    "                   'pass_switch', \n",
    "                   'pass_technique', \n",
    "                   'pass_through_ball',\n",
    "                   'goalkeeper_body_part',\n",
    "                   'goalkeeper_end_location', \n",
    "                   'goalkeeper_outcome', \n",
    "                   'goalkeeper_position', \n",
    "                   'goalkeeper_technique', \n",
    "                   'goalkeeper_type', \n",
    "                   'goalkeeper_penalty_saved_to_post', \n",
    "                   'goalkeeper_shot_saved_to_post', \n",
    "                   'goalkeeper_lost_out', \n",
    "                   'goalkeeper_Clear', \n",
    "                   'goalkeeper_In Play Safe',\n",
    "                   'shot_key_pass_id',\n",
    "                   'shot_one_on_one',\n",
    "                   'shot_end_location',\n",
    "                   'shot_type',\n",
    "                   'pass_angle',\n",
    "                   'pass_body_part',\n",
    "                   'pass_type',\n",
    "                   'pass_length',\n",
    "                   'pass_outswinging',\n",
    "                   'pass_inswinging',\n",
    "                   'pass_cross', \n",
    "                   'pass_cut_back', \n",
    "                   'pass_deflected', \n",
    "                   'pass_goal_assist', \n",
    "                   'pass_recipient', \n",
    "                   'pass_recipient_id', \n",
    "                   'pass_assisted_shot_id', \n",
    "                   'pass_no_touch', \n",
    "                   'pass_end_location', \n",
    "                   'pass_aerial_won',\n",
    "                   'pass_height',\n",
    "                   'substitution_outcome_id',\n",
    "                   'tactics',\n",
    "                   'block_deflection',\n",
    "                   'dribble_no_touch',\n",
    "                   'shot_open_goal', \n",
    "                   'shot_saved_to_post',\n",
    "                   'shot_redirect', \n",
    "                   'shot_follows_dribble',\n",
    "                   'period',\n",
    "                   'injury_stoppage_in_chanin',\n",
    "                   'block_save_block',\n",
    "                   'ball recovery_offensive',\n",
    "\n",
    "\n",
    "                   ]\n",
    "cleaned_df = data.drop_columns(cleaned_df, columns_to_drop)\n",
    "\n",
    "# add lookahead outcome\n",
    "df_with_targets = data.assign_lookahead_outcomes(cleaned_df, lookahead=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-vintage",
   "metadata": {},
   "source": [
    "# Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charming-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-groove",
   "metadata": {},
   "source": [
    "# Finalize NN Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usual-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-nickname",
   "metadata": {},
   "source": [
    "# Neural Network final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "processed-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nn_target  nn_target_int\n",
      "0  Keep Possession              0\n",
      "1  Keep Possession              0\n",
      "2  Keep Possession              0\n",
      "3  Keep Possession              0\n",
      "4  Keep Possession              0\n"
     ]
    }
   ],
   "source": [
    "context_cols = [\n",
    "    'under_pressure', \n",
    "    'counterpress', \n",
    "    'dribble_nutmeg'\n",
    "]\n",
    "\n",
    "# Impute NaN values with 0.0 (float)\n",
    "# This assumes NaN means the event was NOT under pressure, NOT a counterpress, etc.\n",
    "nn_dataset[context_cols] = nn_dataset[context_cols].fillna(0.0)\n",
    "\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "# Check\n",
    "print(nn_dataset[['nn_target', 'nn_target_int']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cooperative-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 72552\n",
      "Total validation samples: 18138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Define the three arrays to split\n",
    "X_features = nn_dataset[layer_columns] # Example feature set\n",
    "event_targets = nn_dataset['nn_target_int'].values\n",
    "goal_flags = nn_dataset['goal_flag'].values\n",
    "\n",
    "VALIDATION_SIZE = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# CRITICAL: Assign the 6 returned arrays to 6 descriptive variables\n",
    "(\n",
    "    X_train, \n",
    "    X_val, \n",
    "    y_event_train, \n",
    "    y_event_val, \n",
    "    y_goal_train, \n",
    "    y_goal_val\n",
    ") = train_test_split(\n",
    "    X_features, \n",
    "    event_targets, \n",
    "    goal_flags,\n",
    "    test_size=VALIDATION_SIZE, \n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=event_targets \n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Instantiate the two PitchDataset objects (using the 6 arrays)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Training Dataset (uses all three 'train' arrays)\n",
    "train_dataset = PitchDatasetMultiTask(\n",
    "    X_train, \n",
    "    y_event_train, \n",
    "    y_goal_train\n",
    ")\n",
    "\n",
    "# Validation Dataset (uses all three 'val' arrays)\n",
    "validation_dataset = PitchDatasetMultiTask(\n",
    "    X_val, \n",
    "    y_event_val, \n",
    "    y_goal_val\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-output",
   "metadata": {},
   "source": [
    "# The Goal Multi Task CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coral-headquarters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Goal Positive Weight (0/1 ratio): 5.00\n",
      "Starting training for Static CNN Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base CNN Threat Epoch 1: 100%|██████████| 2268/2268 [00:13<00:00, 169.97it/s, event_loss=0.954, loss=0.954]\n",
      "Base CNN Threat Epoch 2: 100%|██████████| 2268/2268 [00:12<00:00, 177.08it/s, event_loss=0.464, loss=1.15] \n",
      "Base CNN Threat Epoch 3: 100%|██████████| 2268/2268 [00:12<00:00, 178.20it/s, event_loss=0.628, loss=1.24] \n",
      "Base CNN Threat Epoch 4: 100%|██████████| 2268/2268 [00:12<00:00, 181.81it/s, event_loss=1.13, loss=1.13]  \n",
      "Base CNN Threat Epoch 5: 100%|██████████| 2268/2268 [00:12<00:00, 175.41it/s, event_loss=0.607, loss=0.773]\n",
      "Base CNN Threat Epoch 6: 100%|██████████| 2268/2268 [00:13<00:00, 163.37it/s, event_loss=1.12, loss=1.12]  \n",
      "Base CNN Threat Epoch 7: 100%|██████████| 2268/2268 [00:13<00:00, 167.39it/s, event_loss=0.173, loss=0.596]\n",
      "Base CNN Threat Epoch 8: 100%|██████████| 2268/2268 [00:12<00:00, 174.72it/s, event_loss=1.9, loss=5.14]   \n",
      "Base CNN Threat Epoch 9: 100%|██████████| 2268/2268 [00:12<00:00, 177.71it/s, event_loss=1.03, loss=1.03]  \n",
      "Base CNN Threat Epoch 10: 100%|██████████| 2268/2268 [00:12<00:00, 175.58it/s, event_loss=1.7, loss=1.75]   \n",
      "Base CNN Threat Epoch 11: 100%|██████████| 2268/2268 [00:13<00:00, 170.79it/s, event_loss=0.855, loss=0.855]\n",
      "Base CNN Threat Epoch 12: 100%|██████████| 2268/2268 [00:13<00:00, 171.47it/s, event_loss=0.723, loss=0.723]\n",
      "Base CNN Threat Epoch 13: 100%|██████████| 2268/2268 [00:13<00:00, 169.51it/s, event_loss=0.831, loss=0.831]\n",
      "Base CNN Threat Epoch 14: 100%|██████████| 2268/2268 [00:14<00:00, 160.26it/s, event_loss=0.943, loss=0.943]\n",
      "Base CNN Threat Epoch 15: 100%|██████████| 2268/2268 [00:13<00:00, 167.19it/s, event_loss=1.1, loss=1.1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Check device\n",
    "# -----------------------------\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 1. Define input columns & targets\n",
    "# ------------------------------------\n",
    "# This assumes nn_dataset is already loaded and processed in previous cells.\n",
    "\n",
    "# Ensure labels are in the correct format\n",
    "event_targets = nn_dataset['nn_target_int'].values   # 0=keep, 1=lose, 2=shot (int)\n",
    "# CRITICAL: Goal flags must be float for BCEWithLogitsLoss\n",
    "goal_flags = nn_dataset['goal_flag'].values.astype(np.float32) \n",
    "\n",
    "# -----------------------------\n",
    "# 2. Prepare dataset (Static Input)\n",
    "# -----------------------------\n",
    "# PitchDatasetMultiTask correctly uses the 3 static layer columns.\n",
    "# ------------------------------------\n",
    "# 3. Compute class weights and positive weight\n",
    "# ------------------------------------\n",
    "\n",
    "# A. Event Weights (Multi-Class) - For CrossEntropyLoss\n",
    "event_counts = Counter(event_targets)\n",
    "total_events = len(event_targets)\n",
    "\n",
    "# Using inverse frequency: total / count\n",
    "class_weights_event = torch.tensor(\n",
    "    [total_events / event_counts.get(c, 1) for c in range(len(event_counts))],\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "# B. Goal Positive Weight (Binary) - For BCEWithLogitsLoss\n",
    "goal_counts = Counter(goal_flags)\n",
    "\n",
    "STABLE_GOAL_POS_WEIGHT = 5.0\n",
    "goal_pos_weight = torch.tensor(STABLE_GOAL_POS_WEIGHT, dtype=torch.float32).to(config.DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Train model (Using the dedicated base function)\n",
    "# ------------------------------------\n",
    "print(\"Starting training for Static CNN Baseline...\")\n",
    "baseline_model = train_model_base_threat(\n",
    "    dataset=train_dataset, \n",
    "    event_class_weights=class_weights_event, \n",
    "    goal_pos_weight=goal_pos_weight\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "driven-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Event Outcome Metrics ---\n",
      "Event Accuracy: 0.5772962840445474\n",
      "Event Balanced Accuracy: 0.5991002910321375\n",
      "Event Confusion Matrix:\n",
      " [[7712 3398 1422]\n",
      " [1848 2105  764]\n",
      " [ 118  117  654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.69     12532\n",
      "           1       0.37      0.45      0.41      4717\n",
      "           2       0.23      0.74      0.35       889\n",
      "\n",
      "    accuracy                           0.58     18138\n",
      "   macro avg       0.47      0.60      0.48     18138\n",
      "weighted avg       0.66      0.58      0.60     18138\n",
      "\n",
      "\n",
      "--- Goal Prediction (xG) Metrics ---\n",
      "Goal Accuracy: 0.8312710911136107\n",
      "Goal Balanced Accuracy: 0.7092140979331866\n",
      "Goal AUC-ROC Score: 0.7490862846517194\n",
      "Goal Confusion Matrix:\n",
      " [[673  94]\n",
      " [ 56  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90       767\n",
      "         1.0       0.41      0.54      0.47       122\n",
      "\n",
      "    accuracy                           0.83       889\n",
      "   macro avg       0.67      0.71      0.68       889\n",
      "weighted avg       0.85      0.83      0.84       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Evaluate model\n",
    "# -----------------------------\n",
    "metrics = evaluate_model_base_threat(baseline_model, validation_dataset)\n",
    "# print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joined-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Event Classification Probabilities (P_outcome) ---\n",
      "Shape of Event Probabilities (N, 3): (18138, 3)\n",
      "Average Predicted P(Keep Possession): 0.4683\n",
      "Average Predicted P(Lose Possession): 0.3879\n",
      "Average Predicted P(Shot): 0.1438\n",
      "\n",
      "--- Goal Prediction Probabilities (xG) ---\n",
      "Number of Shots Evaluated: 889\n",
      "Average Predicted xG per Shot: 0.1902\n",
      "Total Predicted xG for all Shots: 169.10\n",
      "Actual Goals Scored (True Goals): 122.00\n",
      "Goal Prediction AUC-ROC Score: 0.7490862846517194\n"
     ]
    }
   ],
   "source": [
    "# Assuming the result of your evaluation is stored here:\n",
    "print(\"--- Event Classification Probabilities (P_outcome) ---\")\n",
    "event_probs = metrics['event_probs']\n",
    "print(f\"Shape of Event Probabilities (N, 3): {event_probs.shape}\")\n",
    "\n",
    "# Average predicted probability for each class (overall confidence)\n",
    "avg_P_keep = np.mean(event_probs[:, 0])\n",
    "avg_P_lose = np.mean(event_probs[:, 1])\n",
    "avg_P_shot = np.mean(event_probs[:, 2])\n",
    "\n",
    "print(f\"Average Predicted P(Keep Possession): {avg_P_keep:.4f}\")\n",
    "print(f\"Average Predicted P(Lose Possession): {avg_P_lose:.4f}\")\n",
    "print(f\"Average Predicted P(Shot): {avg_P_shot:.4f}\")\n",
    "\n",
    "print(\"\\n--- Goal Prediction Probabilities (xG) ---\")\n",
    "goal_probs = metrics['goal_probs']\n",
    "print(f\"Number of Shots Evaluated: {goal_probs.shape[0]}\")\n",
    "\n",
    "# Average Predicted xG\n",
    "avg_xg = np.mean(goal_probs)\n",
    "print(f\"Average Predicted xG per Shot: {avg_xg:.4f}\")\n",
    "\n",
    "# Total Predicted xG (sum of all probabilities for the shot events)\n",
    "total_xg = np.sum(goal_probs)\n",
    "print(f\"Total Predicted xG for all Shots: {total_xg:.2f}\")\n",
    "\n",
    "# The actual number of goals scored in the test set (True Goals)\n",
    "true_goals = np.sum(metrics['goal_labels'])\n",
    "print(f\"Actual Goals Scored (True Goals): {true_goals:.2f}\")\n",
    "\n",
    "# Print AUC Score (Should be in your metrics dictionary now)\n",
    "print(f\"Goal Prediction AUC-ROC Score: {metrics.get('goal_auc', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "athletic-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction on 90690 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Probabilities: 100%|██████████| 89/89 [00:01<00:00, 62.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Prediction complete. Data saved to: baseline_cnn_predictions.parquet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the columns that cause the Parquet error\n",
    "LAYER_COLUMNS_TO_DROP = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "def predict_and_save_probabilities(\n",
    "    model, \n",
    "    full_dataset, \n",
    "    original_df: pd.DataFrame, \n",
    "    output_filepath: str,\n",
    "    device: str = 'cpu',\n",
    "    batch_size: int = 1024\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs the model, computes probabilities, assigns them to the original DataFrame,\n",
    "    drops the problematic pitch layer columns, and saves the result as a Parquet file.\n",
    "    \"\"\"\n",
    "    print(f\"Starting prediction on {len(full_dataset)} samples...\")\n",
    "\n",
    "    model.eval() \n",
    "    model.to(device)\n",
    "    pred_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    event_probs_list = []\n",
    "    goal_probs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, _, _ in tqdm(pred_loader, desc=\"Predicting Probabilities\"):\n",
    "            # If using Contextual Model, adjust the unpacking: for X, ctx, _, _ in ...\n",
    "            X = X.to(device)\n",
    "            event_logits, goal_logits = model(X)\n",
    "            \n",
    "            event_probs = F.softmax(event_logits, dim=1) \n",
    "            event_probs_list.append(event_probs.cpu().numpy())\n",
    "            \n",
    "            goal_probs = torch.sigmoid(goal_logits)\n",
    "            goal_probs_list.append(goal_probs.cpu().numpy())\n",
    "\n",
    "    all_event_probs = np.concatenate(event_probs_list, axis=0)\n",
    "    all_goal_probs = np.concatenate(goal_probs_list, axis=0).flatten()\n",
    "\n",
    "    # 1. Assign new columns to the original DataFrame\n",
    "    result_df = original_df.copy()\n",
    "    \n",
    "    result_df.loc[:, 'P_Lose'] = all_event_probs[:, 1]\n",
    "    result_df.loc[:, 'P_Keep'] = all_event_probs[:, 0]\n",
    "    result_df.loc[:, 'P_Shot'] = all_event_probs[:, 2]\n",
    "    result_df.loc[:, 'xG'] = all_goal_probs\n",
    "    \n",
    "    # 2. CRITICAL FIX: Drop the complex object columns before saving!\n",
    "    # These columns contain lists-of-lists (the pitch layers) which Parquet cannot serialize.\n",
    "    columns_to_keep = [col for col in result_df.columns if col not in LAYER_COLUMNS_TO_DROP]\n",
    "    final_df_to_save = result_df[columns_to_keep]\n",
    "\n",
    "    # 3. Save the enriched DataFrame to Parquet\n",
    "    final_df_to_save.to_parquet(output_filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Prediction complete. Data saved to: {output_filepath}\")\n",
    "    return final_df_to_save\n",
    "\n",
    "# Example: Run the function again\n",
    "# final_df_with_probs = predict_and_save_probabilities(...) # using the fixed function\n",
    "\n",
    "# --- Example Usage (Requires your context setup) ---\n",
    "# NOTE: You will need to create the 'full_dataset' object here:\n",
    "full_dataset = PitchDatasetMultiTask(nn_dataset[layer_columns], event_targets, goal_flags) \n",
    "\n",
    "final_df_with_probs = predict_and_save_probabilities(\n",
    "    model=baseline_model,\n",
    "    full_dataset=full_dataset,\n",
    "    original_df=nn_dataset.copy(),\n",
    "    output_filepath='baseline_cnn_predictions.parquet',\n",
    "    device=DEVICE,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dangerous-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_with_probs\n",
    "\n",
    "COLS_TO_DROP = ['match_id', 'possession', 'under_pressure', 'counter_press', 'dribble_nutmeg'] # Assuming these were also duplicated\n",
    "\n",
    "# 2. Create a clean version of the predictions DF\n",
    "df_preds_clean = final_df_with_probs.drop(columns=COLS_TO_DROP, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handed-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(data_events, df_preds_clean, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "internal-authentication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50_50</th>\n",
       "      <th>ball_receipt_outcome</th>\n",
       "      <th>ball_recovery_recovery_failure</th>\n",
       "      <th>carry_end_location</th>\n",
       "      <th>clearance_aerial_won</th>\n",
       "      <th>clearance_body_part</th>\n",
       "      <th>clearance_head</th>\n",
       "      <th>clearance_left_foot</th>\n",
       "      <th>clearance_other</th>\n",
       "      <th>clearance_right_foot</th>\n",
       "      <th>...</th>\n",
       "      <th>goalkeeper_lost_out</th>\n",
       "      <th>shot_follows_dribble</th>\n",
       "      <th>nn_target</th>\n",
       "      <th>goal_flag</th>\n",
       "      <th>counterpress_y</th>\n",
       "      <th>nn_target_int</th>\n",
       "      <th>P_Lose</th>\n",
       "      <th>P_Keep</th>\n",
       "      <th>P_Shot</th>\n",
       "      <th>xG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448441</td>\n",
       "      <td>0.549075</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208276</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445620</td>\n",
       "      <td>0.388160</td>\n",
       "      <td>0.166219</td>\n",
       "      <td>0.653905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lose Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481475</td>\n",
       "      <td>0.506040</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.004109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590819</td>\n",
       "      <td>0.378169</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90685</th>\n",
       "      <td>{'outcome': {'id': 1, 'name': 'Lost'}}</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lose Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466086</td>\n",
       "      <td>0.533402</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.033038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90686</th>\n",
       "      <td>{'outcome': {'id': 1, 'name': 'Lost'}}</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316368</td>\n",
       "      <td>0.365292</td>\n",
       "      <td>0.318340</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90687</th>\n",
       "      <td>{'outcome': {'id': 4, 'name': 'Won'}}</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keep Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457215</td>\n",
       "      <td>0.444297</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90688</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lose Possession</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558619</td>\n",
       "      <td>0.441226</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90689</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.178818</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.718774</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90690 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        50_50 ball_receipt_outcome  \\\n",
       "0                                        None                 None   \n",
       "1                                        None                 None   \n",
       "2                                        None                 None   \n",
       "3                                        None                 None   \n",
       "4                                        None                 None   \n",
       "...                                       ...                  ...   \n",
       "90685  {'outcome': {'id': 1, 'name': 'Lost'}}                 None   \n",
       "90686  {'outcome': {'id': 1, 'name': 'Lost'}}                 None   \n",
       "90687   {'outcome': {'id': 4, 'name': 'Won'}}                 None   \n",
       "90688                                    None                 None   \n",
       "90689                                    None                 None   \n",
       "\n",
       "       ball_recovery_recovery_failure carry_end_location  \\\n",
       "0                                 NaN               None   \n",
       "1                                 NaN               None   \n",
       "2                                 NaN               None   \n",
       "3                                 NaN               None   \n",
       "4                                 NaN               None   \n",
       "...                               ...                ...   \n",
       "90685                             NaN               None   \n",
       "90686                             NaN               None   \n",
       "90687                             NaN               None   \n",
       "90688                             NaN               None   \n",
       "90689                             NaN               None   \n",
       "\n",
       "       clearance_aerial_won clearance_body_part  clearance_head  \\\n",
       "0                       NaN                None             NaN   \n",
       "1                       NaN                None             NaN   \n",
       "2                       NaN                None             NaN   \n",
       "3                       NaN                None             NaN   \n",
       "4                       NaN                None             NaN   \n",
       "...                     ...                 ...             ...   \n",
       "90685                   NaN                None             NaN   \n",
       "90686                   NaN                None             NaN   \n",
       "90687                   NaN                None             NaN   \n",
       "90688                   NaN                None             NaN   \n",
       "90689                   NaN                None             NaN   \n",
       "\n",
       "       clearance_left_foot  clearance_other  clearance_right_foot  ...  \\\n",
       "0                      NaN              NaN                   NaN  ...   \n",
       "1                      NaN              NaN                   NaN  ...   \n",
       "2                      NaN              NaN                   NaN  ...   \n",
       "3                      NaN              NaN                   NaN  ...   \n",
       "4                      NaN              NaN                   NaN  ...   \n",
       "...                    ...              ...                   ...  ...   \n",
       "90685                  NaN              NaN                   NaN  ...   \n",
       "90686                  NaN              NaN                   NaN  ...   \n",
       "90687                  NaN              NaN                   NaN  ...   \n",
       "90688                  NaN              NaN                   NaN  ...   \n",
       "90689                  NaN              NaN                   NaN  ...   \n",
       "\n",
       "       goalkeeper_lost_out  shot_follows_dribble        nn_target goal_flag  \\\n",
       "0                      NaN                   NaN  Keep Possession         0   \n",
       "1                      NaN                   NaN  Keep Possession         0   \n",
       "2                      NaN                   NaN  Keep Possession         0   \n",
       "3                      NaN                   NaN  Lose Possession         0   \n",
       "4                      NaN                   NaN  Keep Possession         0   \n",
       "...                    ...                   ...              ...       ...   \n",
       "90685                  NaN                   NaN  Lose Possession         0   \n",
       "90686                  NaN                   NaN  Keep Possession         0   \n",
       "90687                  NaN                   NaN  Keep Possession         0   \n",
       "90688                  NaN                   NaN  Lose Possession         0   \n",
       "90689                  NaN                   NaN             Shot         0   \n",
       "\n",
       "      counterpress_y  nn_target_int    P_Lose    P_Keep    P_Shot        xG  \n",
       "0                0.0              0  0.448441  0.549075  0.002484  0.000005  \n",
       "1                0.0              0  0.208276  0.791583  0.000140  0.000005  \n",
       "2                0.0              0  0.445620  0.388160  0.166219  0.653905  \n",
       "3                0.0              1  0.481475  0.506040  0.012485  0.004109  \n",
       "4                0.0              0  0.590819  0.378169  0.031012  0.000002  \n",
       "...              ...            ...       ...       ...       ...       ...  \n",
       "90685            0.0              1  0.466086  0.533402  0.000512  0.033038  \n",
       "90686            1.0              0  0.316368  0.365292  0.318340  0.000060  \n",
       "90687            0.0              0  0.457215  0.444297  0.098488  0.001303  \n",
       "90688            0.0              1  0.558619  0.441226  0.000154  0.002911  \n",
       "90689            0.0              2  0.178818  0.102407  0.718774  0.000027  \n",
       "\n",
       "[90690 rows x 121 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "orange-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4018356 3998852 3998844 3998837]\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the team name\n",
    "TEAM_NAME = \"Switzerland Women's\"\n",
    "\n",
    "# 2. Filter the DataFrame where Switzerland Women's is either the home or away team\n",
    "switzerland_matches = df_merged[\n",
    "    (df_merged['team'] == TEAM_NAME)]\n",
    "\n",
    "# 3. Get all unique match IDs\n",
    "unique_match_ids = switzerland_matches['match_id'].unique()\n",
    "\n",
    "# 4. Print the result\n",
    "print(unique_match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fifteen-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_possession_sequence(\n",
    "    df_merged: pd.DataFrame, \n",
    "    match_id: int, \n",
    "    possession_id: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the merged DataFrame (raw event data + model predictions)\n",
    "    to return a single, chronologically sorted possession sequence.\n",
    "\n",
    "    Args:\n",
    "        df_merged (pd.DataFrame): The pre-loaded DataFrame containing all merged data.\n",
    "        match_id (int): The match identifier to filter on.\n",
    "        possession_id (int): The possession identifier to filter on.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered and sorted sequence DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Filter for the Specific Possession Sequence\n",
    "    # This filters the full DataFrame down to just the events of interest\n",
    "    df_sequence = df_merged[\n",
    "        (df_merged['match_id'] == match_id) & \n",
    "        (df_merged['possession_id'] == possession_id)\n",
    "    ].copy()\n",
    "    \n",
    "    if df_sequence.empty:\n",
    "        print(f\"⚠️ Warning: Sequence not found for Match ID {match_id}, Possession ID {possession_id}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Sort the sequence chronologically\n",
    "    # Assumes a column like 'event_sequence_in_possession' or a reliable timestamp exists.\n",
    "    # If not, use df_sequence.sort_values(by='timestamp', inplace=True)\n",
    "    if 'event_sequence_in_possession' in df_sequence.columns:\n",
    "        df_sequence.sort_values(by='event_sequence_in_possession', inplace=True)\n",
    "    \n",
    "    # 3. Create a clean chronological index for plotting (X-axis)\n",
    "    df_sequence['seq_index'] = np.arange(len(df_sequence))\n",
    "\n",
    "    print(f\"Sequence extracted with {len(df_sequence)} events, ready for plotting.\")\n",
    "    return df_sequence\n",
    "\n",
    "# --- Next Step: Visualization Function ---\n",
    "\n",
    "def plot_possession_threat_stack(df_sequence: pd.DataFrame, title_suffix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Generates a Stacked Area Chart for the Event Head probabilities (P_outcome).\n",
    "    \"\"\"\n",
    "    if df_sequence.empty:\n",
    "        print(\"Cannot plot: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    events = df_sequence['seq_index']\n",
    "    \n",
    "    # Ensure probabilities are present and in the correct order for stacking (Lose at the bottom)\n",
    "    # The stackplot inherently calculates the cumulative lines you requested.\n",
    "    y_lose = df_sequence['P_Lose'].values\n",
    "    y_keep = df_sequence['P_Keep'].values\n",
    "    y_shot = df_sequence['P_Shot'].values\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.stackplot(\n",
    "        events,\n",
    "        y_lose,\n",
    "        y_keep,\n",
    "        y_shot,\n",
    "        labels=['P(Lose Possession)', 'P(Keep Possession)', 'P(Shot)'],\n",
    "        colors=['#ff7f0e', '#1f77b4', '#2ca02c'], # Orange, Blue, Green\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Add xG values as a secondary line plot for context\n",
    "    ax.plot(events, df_sequence['xG'].values, color='red', linestyle='--', linewidth=2, label='xG (P(Goal) | Shot)')\n",
    "\n",
    "    # --- Add Labels and Title ---\n",
    "    match_id = df_sequence['match_id'].iloc[0]\n",
    "    possession_id = df_sequence['possession_id'].iloc[0]\n",
    "    \n",
    "    ax.set_xlabel(f\"Event Index (Relative to Possession Start) | Total Events: {len(df_sequence)}\", fontsize=12)\n",
    "    ax.set_ylabel(\"Probability / Risk Profile\")\n",
    "    ax.set_title(f\"Threat Model Output (P_outcome) for Match {match_id}, Possession {possession_id} {title_suffix}\", fontsize=14)\n",
    "    \n",
    "    ax.legend(loc='upper right', frameon=True)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Set X-ticks clearly for every 5th event, or just the start/end if the possession is very long\n",
    "    if len(events) < 30:\n",
    "        ax.set_xticks(events[::2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Example Usage (How you would run this in your notebook) ---\n",
    "\n",
    "# 1. ASSUME df_merged IS AVAILABLE\n",
    "# 2. Define your target sequence\n",
    "# TARGET_MATCH = 12345\n",
    "# TARGET_POSSESSION = 50\n",
    "\n",
    "# 3. Get the sequence data\n",
    "# sequence_data = get_possession_sequence(\n",
    "#     df_merged=df_merged,\n",
    "#     match_id=TARGET_MATCH,\n",
    "#     possession_id=TARGET_POSSESSION\n",
    "# )\n",
    "\n",
    "# 4. Plot the results\n",
    "# if not sequence_data.empty:\n",
    "#     plot_possession_threat_stack(sequence_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PixlBall Project)",
   "language": "python",
   "name": "pixlball"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
