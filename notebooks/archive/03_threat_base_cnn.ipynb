{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mysterious-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo_root: c:\\Users\\jonas\\Desktop\\repos\\pixlball\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Try to locate the repository root by searching upward for a 'src' directory (or .git)\n",
    "def find_repo_root(start_path=None, marker_dirs=('src', '.git')):\n",
    "    p = os.path.abspath(start_path or os.getcwd())\n",
    "    while True:\n",
    "        if any(os.path.isdir(os.path.join(p, m)) for m in marker_dirs):\n",
    "            return p\n",
    "        parent = os.path.dirname(p)\n",
    "        if parent == p:\n",
    "            return None\n",
    "        p = parent\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "# Fallback to previous hardcoded path working on nuvolos\n",
    "if repo_root is None:\n",
    "    repo_root = \"/files/pixlball\"\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f\"Using repo_root: {repo_root}\")\n",
    "\n",
    "# --- 2. Project Module Imports ---\n",
    "# Import all project modules using clean names\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.evaluate as evaluate\n",
    "import src.data as data\n",
    "import src.losses as losses\n",
    "import src.model as model\n",
    "import src.utils as utils\n",
    "\n",
    "# --- 3. Module Reloading (CRITICAL for Notebook Development) ---\n",
    "# Reload dependencies in order: Config/Utils -> Data/Losses/Model -> Train/Dataset/Evaluate\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(model)\n",
    "importlib.reload(losses) \n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "# --- 4. Direct Imports (For clean code in subsequent cells) ---\n",
    "# Import essential classes and functions needed for the pipeline steps\n",
    "\n",
    "# Configuration\n",
    "from src.config import DEVICE \n",
    "\n",
    "# Data/Dataset Classes\n",
    "from src.dataset import PitchDatasetMultiTask, ContextPitchDatasetMultiTask\n",
    "\n",
    "# Training Functions\n",
    "from src.train import train_model_base_threat\n",
    "\n",
    "# Evaluation/Helpers\n",
    "from src.evaluate import evaluate_model_base_threat\n",
    "from src.losses import get_model_criteria\n",
    "from src.model import TinyCNN_MultiTask_Threat\n",
    "from src.utils import get_sequence_lengths\n",
    "\n",
    "# --- Final Check ---\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documented-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8e470",
   "metadata": {},
   "source": [
    "## Prepare Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3947fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462 events.\n",
      "counts of each outcome nn_target\n",
      "Keep Possession    70920\n",
      "Lose Possession    27465\n",
      "Shot                4764\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_with_targets = data.event_data_loader(data_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-sacrifice",
   "metadata": {},
   "source": [
    "## Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-brass",
   "metadata": {},
   "source": [
    "# Finalize NN Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proprietary-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-negotiation",
   "metadata": {},
   "source": [
    "# Neural Network final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02d9d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data)\n",
    "\n",
    "nn_dataset = data.add_context_cols(nn_dataset)\n",
    "nn_dataset = data.add_target_as_int(nn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "democratic-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 72117\n",
      "Total validation samples: 18030\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Define your split parameters\n",
    "VALIDATION_SIZE = 0.20\n",
    "RANDOM_SEED = 42\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# 2. Split the entire DataFrame first\n",
    "# This keeps features, event targets, and goal flags bundled together\n",
    "train_df, val_df = train_test_split(\n",
    "    nn_dataset, \n",
    "    test_size=VALIDATION_SIZE, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=nn_dataset['nn_target_int']\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Extract the arrays and Instantiate the Datasets (FIXED)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset = PitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values         # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset = PitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-immigration",
   "metadata": {},
   "source": [
    "# The Goal Multi Task CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e38304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_event, goal_pos_weight = utils.get_multitask_loss_weights(nn_dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "concrete-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Positive Weight (0/1 ratio): 5.00\n",
      "Starting training for Static CNN Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base CNN Threat Epoch 1: 100%|██████████| 2254/2254 [00:37<00:00, 60.70it/s, ev_loss=1.0336, loss=1.7891] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# 4. Train model (Using the dedicated base function)\n",
    "# ------------------------------------\n",
    "print(\"Starting training for Static CNN Baseline...\")\n",
    "baseline_model = train_model_base_threat(\n",
    "    dataset=train_dataset, \n",
    "    event_class_weights=class_weights_event, \n",
    "    goal_pos_weight=goal_pos_weight\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "olympic-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Event Outcome Metrics ---\n",
      "Event Accuracy: 0.5128674431503051\n",
      "Event Balanced Accuracy: 0.5821633311450194\n",
      "Event Confusion Matrix:\n",
      " [[6520 4194 1774]\n",
      " [1687 2029  941]\n",
      " [ 105   82  698]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.63     12488\n",
      "           1       0.32      0.44      0.37      4657\n",
      "           2       0.20      0.79      0.32       885\n",
      "\n",
      "    accuracy                           0.51     18030\n",
      "   macro avg       0.44      0.58      0.44     18030\n",
      "weighted avg       0.64      0.51      0.55     18030\n",
      "\n",
      "\n",
      "--- Goal Prediction (xG) Metrics ---\n",
      "Goal Accuracy: 0.8723163841807909\n",
      "Goal Balanced Accuracy: 0.5\n",
      "Goal AUC-ROC Score: 0.6118001742399926\n",
      "Goal Confusion Matrix:\n",
      " [[772   0]\n",
      " [113   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93       772\n",
      "         1.0       0.00      0.00      0.00       113\n",
      "\n",
      "    accuracy                           0.87       885\n",
      "   macro avg       0.44      0.50      0.47       885\n",
      "weighted avg       0.76      0.87      0.81       885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Evaluate model\n",
    "# -----------------------------\n",
    "metrics = evaluate_model_base_threat(baseline_model, validation_dataset)\n",
    "# print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
