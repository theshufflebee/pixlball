{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recreational-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Absolute path to repo root (adjust if necessary)\n",
    "repo_root = \"/files/pixlball\"\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root) \n",
    "\n",
    "# --- 2. Project Module Imports ---\n",
    "# Import all project modules using clean names\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.evaluate as evaluate\n",
    "import src.data as data\n",
    "import src.losses as losses\n",
    "import src.model as model\n",
    "import src.utils as utils\n",
    "\n",
    "# --- 3. Module Reloading (CRITICAL for Notebook Development) ---\n",
    "# Reload dependencies in order: Config/Utils -> Data/Losses/Model -> Train/Dataset/Evaluate\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(model)\n",
    "importlib.reload(losses) \n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "# --- 4. Direct Imports (For clean code in subsequent cells) ---\n",
    "# Import essential classes and functions needed for the pipeline steps\n",
    "\n",
    "# Configuration\n",
    "from src.config import DEVICE \n",
    "\n",
    "# Data/Dataset Classes\n",
    "from src.dataset import PitchDatasetMultiTask, TemporalPitchDataset, ContextPitchDatasetMultiTask, FusionPitchDataset\n",
    "\n",
    "# Training Functions\n",
    "from src.train import train_model_base, train_model_lstm, train_model_context, train_model_lstm_fused\n",
    "\n",
    "# Evaluation/Helpers\n",
    "from src.evaluate import evaluate_model_base, evaluate_model_lstm, evaluate_model_context, evaluate_model_lstm_fused\n",
    "from src.losses import get_model_criteria\n",
    "from src.model import TinyCNN_MultiTask, HybridCNN_LSTM, TinyCNN_LSTM_Fused\n",
    "from src.utils import get_sequence_lengths\n",
    "\n",
    "# --- Final Check ---\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greater-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278 events.\n"
     ]
    }
   ],
   "source": [
    "admin_events = [\n",
    "        'Starting XI', 'Half Start', 'Half End', 'Player On', 'Player Off',\n",
    "        'Substitution', 'Tactical Shift', 'Referee Ball-Drop', 'Injury Stoppage',\n",
    "        'Bad Behaviour', 'Shield'\n",
    "    ]\n",
    "\n",
    "cleaned_df = data.drop_events(data_events, rows_to_drop=admin_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indie-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of each outcome nn_target\n",
      "Keep Possession    71251\n",
      "Lose Possession    28252\n",
      "Shot                4830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "columns_to_drop = ['clearance_body_part',\n",
    "                   'clearance_head',\n",
    "                   'clearance_left_foot',\n",
    "                   'clearance_other',\n",
    "                   'clearance_right_foot',\n",
    "                   'shot_technique',\n",
    "                   'substitution_replacement_id',\n",
    "                   'substitution_replacement',\n",
    "                   'substitution_outcome',\n",
    "                   'shot_saved_off_target',\n",
    "                   'pass_miscommunication',\n",
    "                   'goalkeeper_shot_saved_off_target',\n",
    "                   'goalkeeper_punched_out',\n",
    "                   'shot_first_time',\n",
    "                   'shot_first_time',\n",
    "                   'shot_body_part',\n",
    "                   'related_events',\n",
    "                   'pass_shot_assist', \n",
    "                   'pass_straight', \n",
    "                   'pass_switch', \n",
    "                   'pass_technique', \n",
    "                   'pass_through_ball',\n",
    "                   'goalkeeper_body_part',\n",
    "                   'goalkeeper_end_location', \n",
    "                   'goalkeeper_outcome', \n",
    "                   'goalkeeper_position', \n",
    "                   'goalkeeper_technique', \n",
    "                   'goalkeeper_type', \n",
    "                   'goalkeeper_penalty_saved_to_post', \n",
    "                   'goalkeeper_shot_saved_to_post', \n",
    "                   'goalkeeper_lost_out', \n",
    "                   'goalkeeper_Clear', \n",
    "                   'goalkeeper_In Play Safe',\n",
    "                   'shot_key_pass_id',\n",
    "                   'shot_one_on_one',\n",
    "                   'shot_end_location',\n",
    "                   'shot_type',\n",
    "                   'pass_angle',\n",
    "                   'pass_body_part',\n",
    "                   'pass_type',\n",
    "                   'pass_length',\n",
    "                   'pass_outswinging',\n",
    "                   'pass_inswinging',\n",
    "                   'pass_cross', \n",
    "                   'pass_cut_back', \n",
    "                   'pass_deflected', \n",
    "                   'pass_goal_assist', \n",
    "                   'pass_recipient', \n",
    "                   'pass_recipient_id', \n",
    "                   'pass_assisted_shot_id', \n",
    "                   'pass_no_touch', \n",
    "                   'pass_end_location', \n",
    "                   'pass_aerial_won',\n",
    "                   'pass_height',\n",
    "                   'substitution_outcome_id',\n",
    "                   'tactics',\n",
    "                   'block_deflection',\n",
    "                   'dribble_no_touch',\n",
    "                   'shot_open_goal', \n",
    "                   'shot_saved_to_post',\n",
    "                   'shot_redirect', \n",
    "                   'shot_follows_dribble',\n",
    "                   'period',\n",
    "                   'injury_stoppage_in_chanin',\n",
    "                   'block_save_block',\n",
    "                   'ball recovery_offensive',\n",
    "\n",
    "\n",
    "                   ]\n",
    "cleaned_df = data.drop_columns(cleaned_df, columns_to_drop)\n",
    "\n",
    "# add lookahead outcome\n",
    "df_with_targets = data.assign_lookahead_outcomes(cleaned_df, lookahead=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-nerve",
   "metadata": {},
   "source": [
    "# Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "necessary-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-hanging",
   "metadata": {},
   "source": [
    "# Finalize NN Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "breeding-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-algebra",
   "metadata": {},
   "source": [
    "# Neural Network final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suburban-belly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nn_target  nn_target_int\n",
      "0  Keep Possession              0\n",
      "1  Keep Possession              0\n",
      "2  Keep Possession              0\n",
      "3  Keep Possession              0\n",
      "4  Keep Possession              0\n"
     ]
    }
   ],
   "source": [
    "context_cols = [\n",
    "    'under_pressure', \n",
    "    'counterpress', \n",
    "    'dribble_nutmeg'\n",
    "]\n",
    "\n",
    "# Impute NaN values with 0.0 (float)\n",
    "# This assumes NaN means the event was NOT under pressure, NOT a counterpress, etc.\n",
    "nn_dataset[context_cols] = nn_dataset[context_cols].fillna(0.0)\n",
    "\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "# Check\n",
    "print(nn_dataset[['nn_target', 'nn_target_int']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-female",
   "metadata": {},
   "source": [
    "# The LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "celtic-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Goal Positive Weight (0/1 ratio): 168.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "#layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Get your existing targets\n",
    "event_targets = nn_dataset['nn_target_int'].values\n",
    "goal_flags = nn_dataset['goal_flag'].values.astype(np.float32) # Ensure targets are float\n",
    "\n",
    "# Weights\n",
    "event_counts = Counter(event_targets)\n",
    "total_events = len(event_targets)\n",
    "\n",
    "# Using inverse frequency: total / count\n",
    "class_weights_event = torch.tensor(\n",
    "    [total_events / event_counts.get(c, 1) for c in range(len(event_counts))],\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "# B. Goal Positive Weight (Binary) - For BCEWithLogitsLoss\n",
    "goal_counts = Counter(goal_flags)\n",
    "# CRITICAL: pos_weight = (Number of Negative Samples) / (Number of Positive Samples)\n",
    "# Here: pos_weight = (Number of No Goals) / (Number of Goals)\n",
    "goal_pos_weight = torch.tensor(\n",
    "    goal_counts.get(0.0, 1) / goal_counts.get(1.0, 1),\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earlier-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 5D Sequential Dataset for LSTM...\n",
      "         nn_target  nn_target_int\n",
      "0  Keep Possession              0\n",
      "1  Keep Possession              0\n",
      "2  Keep Possession              0\n",
      "3  Keep Possession              0\n",
      "4  Keep Possession              0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Prepare Sequential Dataset\n",
    "# -----------------------------\n",
    "print(\"Preparing 5D Sequential Dataset for LSTM...\")\n",
    "\n",
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag', 'possession']) # adjust cols depending on model\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "# Check\n",
    "print(nn_dataset[['nn_target', 'nn_target_int']].head())\n",
    "\n",
    "windows = data.build_temporal_windows_with_mask(nn_dataset)\n",
    "\n",
    "# Assuming 'windows' variable holds the output of data.build_temporal_windows_with_mask()\n",
    "# Shape: (Num_Events, T, 4, H, W)\n",
    "temporal_dataset = TemporalPitchDataset(\n",
    "    windows=windows, \n",
    "    event_labels=event_targets, \n",
    "    goal_flags=goal_flags\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "traditional-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSTM Epoch 1:   0%|          | 0/9069 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for Hybrid CNN-LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSTM Epoch 1: 100%|██████████| 9069/9069 [01:07<00:00, 133.91it/s, event_loss=1.19, loss=19, shot_loss=3.57]  \n",
      "LSTM Epoch 2: 100%|██████████| 9069/9069 [01:16<00:00, 118.15it/s, event_loss=1.28, loss=16.4, shot_loss=3.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid CNN-LSTM Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train Hybrid CNN-LSTM Model\n",
    "# -----------------------------\n",
    "print(\"Starting training for Hybrid CNN-LSTM...\")\n",
    "lstm_model = train_model_lstm(\n",
    "    dataset=temporal_dataset, \n",
    "    event_class_weights=class_weights_event, \n",
    "    goal_pos_weight=goal_pos_weight\n",
    ")\n",
    "print(\"Hybrid CNN-LSTM Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grave-organic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM Model on training data...\n",
      "Event Accuracy: 0.6909141029882016\n",
      "Event Balanced Accuracy: 0.3333333333333333\n",
      "Event Confusion Matrix:\n",
      " [[62659     0     0]\n",
      " [23584     0     0]\n",
      " [ 4447     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82     62659\n",
      "           1       0.00      0.00      0.00     23584\n",
      "           2       0.00      0.00      0.00      4447\n",
      "\n",
      "    accuracy                           0.69     90690\n",
      "   macro avg       0.23      0.33      0.27     90690\n",
      "weighted avg       0.48      0.69      0.56     90690\n",
      "\n",
      "Goal Accuracy: 0.12030582415111311\n",
      "Goal Balanced Accuracy: 0.5\n",
      "Goal AUC-ROC Score: 0.4716506125413298\n",
      "Goal Confusion Matrix:\n",
      " [[   0 3912]\n",
      " [   0  535]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3912\n",
      "         1.0       0.12      1.00      0.21       535\n",
      "\n",
      "    accuracy                           0.12      4447\n",
      "   macro avg       0.06      0.50      0.11      4447\n",
      "weighted avg       0.01      0.12      0.03      4447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Evaluate LSTM Model\n",
    "# -----------------------------\n",
    "print(\"\\nEvaluating LSTM Model on training data...\")\n",
    "metrics = evaluate_model_lstm(lstm_model, temporal_dataset)\n",
    "# print(lstm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "systematic-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Event Classification Probabilities (P_outcome) ---\n",
      "Shape of Event Probabilities (N, 3): (90690, 3)\n",
      "Average Predicted P(Keep Possession): 0.4168\n",
      "Average Predicted P(Lose Possession): 0.4008\n",
      "Average Predicted P(Shot): 0.1824\n",
      "\n",
      "--- Goal Prediction Probabilities (xG) ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a98110965fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Goal Prediction Probabilities (xG) ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgoal_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'goal_probs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Shots Evaluated: {goal_probs.shape[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Average Predicted xG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Event Classification Probabilities (P_outcome) ---\")\n",
    "event_probs = metrics['event_probs']\n",
    "print(f\"Shape of Event Probabilities (N, 3): {event_probs.shape}\")\n",
    "\n",
    "# Average predicted probability for each class (overall confidence)\n",
    "avg_P_keep = np.mean(event_probs[:, 0])\n",
    "avg_P_lose = np.mean(event_probs[:, 1])\n",
    "avg_P_shot = np.mean(event_probs[:, 2])\n",
    "\n",
    "print(f\"Average Predicted P(Keep Possession): {avg_P_keep:.4f}\")\n",
    "print(f\"Average Predicted P(Lose Possession): {avg_P_lose:.4f}\")\n",
    "print(f\"Average Predicted P(Shot): {avg_P_shot:.4f}\")\n",
    "\n",
    "print(\"\\n--- Goal Prediction Probabilities (xG) ---\")\n",
    "goal_probs = metrics['goal_probs']\n",
    "print(f\"Number of Shots Evaluated: {goal_probs.shape[0]}\")\n",
    "\n",
    "# Average Predicted xG\n",
    "avg_xg = np.mean(goal_probs)\n",
    "print(f\"Average Predicted xG per Shot: {avg_xg:.4f}\")\n",
    "\n",
    "# Total Predicted xG (sum of all probabilities for the shot events)\n",
    "total_xg = np.sum(goal_probs)\n",
    "print(f\"Total Predicted xG for all Shots: {total_xg:.2f}\")\n",
    "\n",
    "# The actual number of goals scored in the test set (True Goals)\n",
    "true_goals = np.sum(metrics['goal_labels'])\n",
    "print(f\"Actual Goals Scored (True Goals): {true_goals:.2f}\")\n",
    "\n",
    "# Print AUC Score (Should be in your metrics dictionary now)\n",
    "print(f\"Goal Prediction AUC-ROC Score: {metrics.get('goal_auc', 'N/A')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
