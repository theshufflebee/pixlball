{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romance-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Absolute path to repo root (adjust if necessary)\n",
    "repo_root = \"/files/pixlball\"\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root) \n",
    "\n",
    "# --- 2. Project Module Imports ---\n",
    "# Import all project modules using clean names\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.evaluate as evaluate\n",
    "import src.data as data\n",
    "import src.losses as losses\n",
    "import src.model as model\n",
    "import src.utils as utils\n",
    "\n",
    "# --- 3. Module Reloading (CRITICAL for Notebook Development) ---\n",
    "# Reload dependencies in order: Config/Utils -> Data/Losses/Model -> Train/Dataset/Evaluate\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(model)\n",
    "importlib.reload(losses) \n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "# --- 4. Direct Imports (For clean code in subsequent cells) ---\n",
    "# Import essential classes and functions needed for the pipeline steps\n",
    "\n",
    "# Configuration\n",
    "from src.config import DEVICE \n",
    "\n",
    "# Data/Dataset Classes\n",
    "from src.dataset import PitchDatasetMultiTask, TemporalPitchDataset, ContextPitchDatasetMultiTask, FusionPitchDataset\n",
    "\n",
    "# Training Functions\n",
    "from src.train import train_model_base, train_model_lstm, train_model_context, train_model_lstm_fused\n",
    "\n",
    "# Evaluation/Helpers\n",
    "from src.evaluate import evaluate_model_base, evaluate_model_lstm, evaluate_model_context, evaluate_model_lstm_fused\n",
    "from src.losses import get_model_criteria\n",
    "from src.model import TinyCNN_MultiTask, HybridCNN_LSTM, TinyCNN_LSTM_Fused\n",
    "from src.utils import get_sequence_lengths\n",
    "\n",
    "# --- Final Check ---\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proper-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blond-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278 events.\n"
     ]
    }
   ],
   "source": [
    "admin_events = [\n",
    "        'Starting XI', 'Half Start', 'Half End', 'Player On', 'Player Off',\n",
    "        'Substitution', 'Tactical Shift', 'Referee Ball-Drop', 'Injury Stoppage',\n",
    "        'Bad Behaviour', 'Shield'\n",
    "    ]\n",
    "\n",
    "cleaned_df = data.drop_events(data_events, rows_to_drop=admin_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conscious-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts of each outcome nn_target\n",
      "Keep Possession    71251\n",
      "Lose Possession    28252\n",
      "Shot                4830\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "columns_to_drop = ['clearance_body_part',\n",
    "                   'clearance_head',\n",
    "                   'clearance_left_foot',\n",
    "                   'clearance_other',\n",
    "                   'clearance_right_foot',\n",
    "                   'shot_technique',\n",
    "                   'substitution_replacement_id',\n",
    "                   'substitution_replacement',\n",
    "                   'substitution_outcome',\n",
    "                   'shot_saved_off_target',\n",
    "                   'pass_miscommunication',\n",
    "                   'goalkeeper_shot_saved_off_target',\n",
    "                   'goalkeeper_punched_out',\n",
    "                   'shot_first_time',\n",
    "                   'shot_first_time',\n",
    "                   'shot_body_part',\n",
    "                   'related_events',\n",
    "                   'pass_shot_assist', \n",
    "                   'pass_straight', \n",
    "                   'pass_switch', \n",
    "                   'pass_technique', \n",
    "                   'pass_through_ball',\n",
    "                   'goalkeeper_body_part',\n",
    "                   'goalkeeper_end_location', \n",
    "                   'goalkeeper_outcome', \n",
    "                   'goalkeeper_position', \n",
    "                   'goalkeeper_technique', \n",
    "                   'goalkeeper_type', \n",
    "                   'goalkeeper_penalty_saved_to_post', \n",
    "                   'goalkeeper_shot_saved_to_post', \n",
    "                   'goalkeeper_lost_out', \n",
    "                   'goalkeeper_Clear', \n",
    "                   'goalkeeper_In Play Safe',\n",
    "                   'shot_key_pass_id',\n",
    "                   'shot_one_on_one',\n",
    "                   'shot_end_location',\n",
    "                   'shot_type',\n",
    "                   'pass_angle',\n",
    "                   'pass_body_part',\n",
    "                   'pass_type',\n",
    "                   'pass_length',\n",
    "                   'pass_outswinging',\n",
    "                   'pass_inswinging',\n",
    "                   'pass_cross', \n",
    "                   'pass_cut_back', \n",
    "                   'pass_deflected', \n",
    "                   'pass_goal_assist', \n",
    "                   'pass_recipient', \n",
    "                   'pass_recipient_id', \n",
    "                   'pass_assisted_shot_id', \n",
    "                   'pass_no_touch', \n",
    "                   'pass_end_location', \n",
    "                   'pass_aerial_won',\n",
    "                   'pass_height',\n",
    "                   'substitution_outcome_id',\n",
    "                   'tactics',\n",
    "                   'block_deflection',\n",
    "                   'dribble_no_touch',\n",
    "                   'shot_open_goal', \n",
    "                   'shot_saved_to_post',\n",
    "                   'shot_redirect', \n",
    "                   'shot_follows_dribble',\n",
    "                   'period',\n",
    "                   'injury_stoppage_in_chanin',\n",
    "                   'block_save_block',\n",
    "                   'ball recovery_offensive',\n",
    "\n",
    "\n",
    "                   ]\n",
    "cleaned_df = data.drop_columns(cleaned_df, columns_to_drop)\n",
    "\n",
    "# add lookahead outcome\n",
    "df_with_targets = data.assign_lookahead_outcomes(cleaned_df, lookahead=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-point",
   "metadata": {},
   "source": [
    "# Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medieval-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-hollywood",
   "metadata": {},
   "source": [
    "# Finalize NN Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bigger-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-naples",
   "metadata": {},
   "source": [
    "# Neural Network final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "differential-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nn_target  nn_target_int\n",
      "0  Keep Possession              0\n",
      "1  Keep Possession              0\n",
      "2  Keep Possession              0\n",
      "3  Keep Possession              0\n",
      "4  Keep Possession              0\n"
     ]
    }
   ],
   "source": [
    "context_cols = [\n",
    "    'under_pressure', \n",
    "    'counterpress', \n",
    "    'dribble_nutmeg'\n",
    "]\n",
    "\n",
    "# Impute NaN values with 0.0 (float)\n",
    "# This assumes NaN means the event was NOT under pressure, NOT a counterpress, etc.\n",
    "nn_dataset[context_cols] = nn_dataset[context_cols].fillna(0.0)\n",
    "\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "# Check\n",
    "print(nn_dataset[['nn_target', 'nn_target_int']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-potter",
   "metadata": {},
   "source": [
    "# The LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finite-eight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Goal Positive Weight (0/1 ratio): 168.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "#layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Get your existing targets\n",
    "event_targets = nn_dataset['nn_target_int'].values\n",
    "goal_flags = nn_dataset['goal_flag'].values.astype(np.float32) # Ensure targets are float\n",
    "\n",
    "# Weights\n",
    "event_counts = Counter(event_targets)\n",
    "total_events = len(event_targets)\n",
    "\n",
    "# Using inverse frequency: total / count\n",
    "class_weights_event = torch.tensor(\n",
    "    [total_events / event_counts.get(c, 1) for c in range(len(event_counts))],\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "# B. Goal Positive Weight (Binary) - For BCEWithLogitsLoss\n",
    "goal_counts = Counter(goal_flags)\n",
    "# CRITICAL: pos_weight = (Number of Negative Samples) / (Number of Positive Samples)\n",
    "# Here: pos_weight = (Number of No Goals) / (Number of Goals)\n",
    "goal_pos_weight = torch.tensor(\n",
    "    goal_counts.get(0.0, 1) / goal_counts.get(1.0, 1),\n",
    "    dtype=torch.float32\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brave-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 5D Sequential Dataset for LSTM...\n",
      "         nn_target  nn_target_int\n",
      "0  Keep Possession              0\n",
      "1  Keep Possession              0\n",
      "2  Keep Possession              0\n",
      "3  Keep Possession              0\n",
      "4  Keep Possession              0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Prepare Sequential Dataset\n",
    "# -----------------------------\n",
    "print(\"Preparing 5D Sequential Dataset for LSTM...\")\n",
    "\n",
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag', 'possession']) # adjust cols depending on model\n",
    "\n",
    "target_map = {\"Keep Possession\": 0, \"Lose Possession\": 1, \"Shot\": 2}\n",
    "\n",
    "# Apply mapping\n",
    "nn_dataset['nn_target_int'] = nn_dataset['nn_target'].map(target_map)\n",
    "\n",
    "# Check\n",
    "print(nn_dataset[['nn_target', 'nn_target_int']].head())\n",
    "\n",
    "windows = data.build_temporal_windows_with_mask(nn_dataset)\n",
    "\n",
    "# Assuming 'windows' variable holds the output of data.build_temporal_windows_with_mask()\n",
    "# Shape: (Num_Events, T, 4, H, W)\n",
    "temporal_dataset = TemporalPitchDataset(\n",
    "    windows=windows, \n",
    "    event_labels=event_targets, \n",
    "    goal_flags=goal_flags\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "revolutionary-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSTM Epoch 1:   0%|          | 12/9069 [00:00<01:19, 114.55it/s, event_loss=1.07, loss=1.07, shot_loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for Hybrid CNN-LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSTM Epoch 1: 100%|██████████| 9069/9069 [01:15<00:00, 120.16it/s, event_loss=1.29, loss=44.4, shot_loss=8.62]  \n",
      "LSTM Epoch 2: 100%|██████████| 9069/9069 [01:23<00:00, 109.14it/s, event_loss=0.934, loss=0.934, shot_loss=0]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid CNN-LSTM Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train Hybrid CNN-LSTM Model\n",
    "# -----------------------------\n",
    "print(\"Starting training for Hybrid CNN-LSTM...\")\n",
    "lstm_model = train_model_lstm(\n",
    "    dataset=temporal_dataset, \n",
    "    event_class_weights=class_weights_event, \n",
    "    goal_pos_weight=goal_pos_weight\n",
    ")\n",
    "print(\"Hybrid CNN-LSTM Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "african-flower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM Model on training data...\n",
      "Event Accuracy: 0.6909141029882016\n",
      "Event Balanced Accuracy: 0.3333333333333333\n",
      "Event Confusion Matrix:\n",
      " [[62659     0     0]\n",
      " [23584     0     0]\n",
      " [ 4447     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82     62659\n",
      "           1       0.00      0.00      0.00     23584\n",
      "           2       0.00      0.00      0.00      4447\n",
      "\n",
      "    accuracy                           0.69     90690\n",
      "   macro avg       0.23      0.33      0.27     90690\n",
      "weighted avg       0.48      0.69      0.56     90690\n",
      "\n",
      "Goal Accuracy: 0.12030582415111311\n",
      "Goal Balanced Accuracy: 0.5\n",
      "Goal Confusion Matrix:\n",
      " [[   0 3912]\n",
      " [   0  535]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3912\n",
      "         1.0       0.12      1.00      0.21       535\n",
      "\n",
      "    accuracy                           0.12      4447\n",
      "   macro avg       0.06      0.50      0.11      4447\n",
      "weighted avg       0.01      0.12      0.03      4447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Evaluate LSTM Model\n",
    "# -----------------------------\n",
    "print(\"\\nEvaluating LSTM Model on training data...\")\n",
    "lstm_metrics = evaluate_model_lstm(lstm_model, temporal_dataset)\n",
    "# print(lstm_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
