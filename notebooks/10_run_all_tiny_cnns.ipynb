{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "settled-relaxation",
   "metadata": {},
   "source": [
    "# Run all Tiny CNNs\n",
    "\n",
    "This file runs all CNNs that are 2d, with and without context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wooden-calgary",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e9fcc165485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "# 1. Load standard libraries FIRST\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. Path Setup ---\n",
    "# Try to locate the repository root by searching upward for a 'src' directory (or .git)\n",
    "def find_repo_root(start_path=None, marker_dirs=('src', '.git')):\n",
    "    p = os.path.abspath(start_path or os.getcwd())\n",
    "    while True:\n",
    "        if any(os.path.isdir(os.path.join(p, m)) for m in marker_dirs):\n",
    "            return p\n",
    "        parent = os.path.dirname(p)\n",
    "        if parent == p:\n",
    "            return None\n",
    "        p = parent\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "# Fallback to previous hardcoded path working on nuvolos\n",
    "if repo_root is None:\n",
    "    repo_root = \"/files/pixlball\"\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f\"Using repo_root: {repo_root}\")\n",
    "\n",
    "import src.data as data\n",
    "import src.model as model\n",
    "import src.train as train\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.evaluate as evaluate\n",
    "import src.utils as utils\n",
    "import src.plotfunctions as plotfunctions\n",
    "import src.losses as losses\n",
    "\n",
    "from src.config import DEVICE \n",
    "\n",
    "\n",
    "# 4. Force a clean reload of your specific logic\n",
    "importlib.reload(data)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(plotfunctions)\n",
    "importlib.reload(losses)\n",
    "importlib.reload(config)\n",
    "\n",
    "\n",
    "utils.enforce_replicability(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_targets = data.event_data_loader(data_events)\n",
    "data_events = None # save memory\n",
    "df_with_targets = data.add_ball_trajectory_features(df_with_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-letter",
   "metadata": {},
   "source": [
    "## Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_360 = data.assign_grid_cells(data_360)\n",
    "data_360 = None # save memory\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-firmware",
   "metadata": {},
   "source": [
    "## Finalize Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model\n",
    "nn_dataset = data.add_context_cols(nn_dataset)\n",
    "nn_dataset = data.add_target_as_int(nn_dataset)\n",
    "nn_dataset, vector_names = data.add_ball_coordinates(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-peeing",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "class_weights_event, goal_pos_weight = utils.get_multitask_loss_weights(nn_dataset, DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-sheet",
   "metadata": {},
   "source": [
    "# Prepare Datasets for CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Use this to prepare your datasets for the final 10-epoch run\n",
    "train_df, val_df = utils.perform_replicable_split(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-definition",
   "metadata": {},
   "source": [
    "## Run the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset = dataset.PitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values         # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset = dataset.PitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset)}\")\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the architecture from the 'arch' module\n",
    "# We name the variable 'baseline_model' to be even clearer\n",
    "import src.model as arch\n",
    "import src.losses as losses\n",
    "from torch.utils.data import DataLoader, Dataset  # <--- Add this line\n",
    "\n",
    "baseline_model = arch.TinyCNN_MultiTask_Threat(\n",
    "    config.GRID_HEIGHT, \n",
    "    config.GRID_WIDTH, \n",
    "    config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# 2. Setup criteria\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# 3. Train using your unified function\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Note: train_multi_task_model should be in your main script or a 'utils' file\n",
    "baseline_model = train.train_multi_task_model(\n",
    "    baseline_model, \n",
    "    train_loader, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.BASELINE_NUM_EPOCHS,\n",
    "    \"Baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the results for your table\n",
    "final_results = {}\n",
    "\n",
    "# 1. Baseline\n",
    "final_results['Baseline'] = evaluate.evaluate_paper_metrics(baseline_model, validation_dataset, \"Baseline 2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model\n",
    "res = evaluate.get_predictions(baseline_model, validation_dataset)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Baseline CNN\", \"figures/baseline_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Baseline CNN\", \"figures/baseline_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-sierra",
   "metadata": {},
   "source": [
    "## Run the Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_features = ['under_pressure', 'counterpress', 'dribble_nutmeg']\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[context_features]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[context_features]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_context)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. INITIALIZE CONTEXTUAL ARCHITECTURE ---\n",
    "# Calculate how many features are in your context (e.g., 8 for ball vector)\n",
    "num_ctx = len(context_features)\n",
    "\n",
    "context_model = arch.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=num_ctx\n",
    ")\n",
    "\n",
    "# --- 3. SETUP CRITERIA ---\n",
    "# We reuse the same logic as the baseline\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# --- 4. TRAIN USING UNIFIED FUNCTION ---\n",
    "# The train_multi_task_model function you have is already 'unified' \n",
    "# It will detect the 4 items from the loader and pass context to the model automatically.\n",
    "train_loader_ctx = DataLoader(train_dataset_context, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "context_model = train.train_multi_task_model(\n",
    "    context_model, \n",
    "    train_loader_ctx, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    config.CONTEXT_NUM_EPOCHS,\n",
    "    \"Contextual-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Situational Context\n",
    "final_results['Context-Situational'] = evaluate.evaluate_paper_metrics(context_model, validation_dataset_context, \"Situational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model\n",
    "res = evaluate.get_predictions(context_model, validation_dataset_context)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Context CNN\", \"figures/context_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Context CNN\", \"figures/context_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-project",
   "metadata": {},
   "source": [
    "## Run the Ball Vector Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. Extract the arrays and Instantiate the Datasets (FIXED)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "## NAME KINETIC DATASET / KINETIC MODEL\n",
    "train_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[vector_names]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[vector_names]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_kinetic)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_kinetic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as arch\n",
    "import src.losses as losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. INITIALIZE KINETIC ARCHITECTURE ---\n",
    "# Identify number of features in your ball vector (e.g., 8)\n",
    "# Ensure 'train_kinetic_dataset' is the one containing your normalized ball vectors\n",
    "num_kinetic_features = 8\n",
    "\n",
    "kinetic_model = arch.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=num_kinetic_features\n",
    ")\n",
    "\n",
    "# Setup all weights / Criteria\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# Load the Data for Training\n",
    "# The train_loader must be built from your kinetic dataset\n",
    "train_loader_kin = DataLoader(train_dataset_kinetic, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Run the unified training function\n",
    "kinetic_model = train.train_multi_task_model(\n",
    "    kinetic_model, \n",
    "    train_loader_kin, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.KINETIC_NUM_EPOCHS,\n",
    "    \"Kinetic-Vector-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Kinetic Model\n",
    "final_results['Context-Kinetic'] = evaluate.evaluate_paper_metrics(kinetic_model, validation_dataset_kinetic, \"Kinetic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model (e.g., Kinetic)\n",
    "res = evaluate.get_predictions(kinetic_model, validation_dataset_kinetic)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Kinetic CNN\", \"figures/kinetic_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Kinetic CNN\", \"figures/kinetic_goal_cm.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-hazard",
   "metadata": {},
   "source": [
    "# Run 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate the 4D Voxels (Channels, Time, Height, Width)\n",
    "# Lookback 3 = 4 frames total (t, t-1, t-2, t-3)\n",
    "voxels_list = data.generate_temporal_voxels(nn_dataset, lookback=3)\n",
    "\n",
    "# 2. Add as a column\n",
    "nn_dataset['temporal_voxel'] = voxels_list\n",
    "\n",
    "train_df, test_df = utils.perform_replicable_split(nn_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_3d = dataset.VoxelPitchDataset(train_df)\n",
    "test_dataset_3d = dataset.VoxelPitchDataset(test_df)\n",
    "\n",
    "# SMOKE TEST: Check the shape of the first item\n",
    "voxel, event, goal = train_dataset_3d[0]\n",
    "print(f\"Voxel Shape: {voxel.shape}\") # MUST be [3, 4, 12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_weights = [0.69, 1.15, 6.7]\n",
    "class_weights_event = torch.tensor(event_weights, dtype=torch.float32).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "import src.model as arch # issues with imports -> workarround\n",
    "importlib.reload(arch)\n",
    "\n",
    "# --- 1. INITIALIZE 3D ARCHITECTURE ---\n",
    "# This model expects a voxel volume (e.g., 4 frames of spatial grids)\n",
    "voxel_model = arch.Tiny3DCNN_MultiTask(\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# --- 2. SETUP CRITERIA ---\n",
    "# Standardize the loss to ensure a fair comparison with the 2D models\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# --- 3. TRAIN ---\n",
    "# The train_loader must be built from your 3D Voxel dataset\n",
    "# Ensure your 3D dataset returns (voxels, event_targets, goal_targets)\n",
    "train_loader_3d = DataLoader(train_dataset_3d, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# The unified training function will see 3 items (Voxels, Event, Goal)\n",
    "# and treat 'Voxels' as the single 'inputs' argument.\n",
    "voxel_model = train.train_multi_task_model(\n",
    "    voxel_model, \n",
    "    train_loader_3d, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    10,\n",
    "    \"3D-Voxel-CNN\",\n",
    "    lr = config.LR_3D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-hammer",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate 3D CNN\n",
    "final_results['3D-Voxel'] = evaluate.evaluate_paper_metrics(voxel_model, test_dataset_3d, \"3D CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for a specific model (e.g., Kinetic)\n",
    "res = evaluate.get_predictions(voxel_model, test_dataset_3d)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Voxel CNN\", \"figures/voxel_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Voxel CNN\", \"figures/voxel_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-affect",
   "metadata": {},
   "source": [
    "# Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you've run the function for all 4 models as final_results['ModelName']\n",
    "# Example: final_results['Baseline'] = evaluate_paper_metrics(baseline_model, val_dataset, \"Baseline\")\n",
    "\n",
    "# Convert results dictionary to a clean DataFrame\n",
    "df_results = pd.DataFrame(final_results).T\n",
    "\n",
    "# Reorder columns for the paper\n",
    "columns_order = [\"Accuracy\", \"Balanced Acc\", \"Recall_Keep\", \"Recall_Loss\", \"Recall_Shot\", \"Goal AUC\"]\n",
    "df_results = df_results[columns_order]\n",
    "\n",
    "df_results.to_csv(\"model_comparison_table.csv\", index=False)\n",
    "\n",
    "print(\"\\nFINAL UTILITY COMPARISON TABLE\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-roommate",
   "metadata": {},
   "source": [
    "# Plots of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves over the same file, keeping your LaTeX document stable\n",
    "plotfunctions.plot_2d_channels_separated(train_dataset, save_path=\"figures/channel_visualization.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
