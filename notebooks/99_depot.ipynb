{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the result of your evaluation is stored here:\n",
    "print(\"--- Event Classification Probabilities (P_outcome) ---\")\n",
    "event_probs = metrics['event_probs']\n",
    "print(f\"Shape of Event Probabilities (N, 3): {event_probs.shape}\")\n",
    "\n",
    "# Average predicted probability for each class (overall confidence)\n",
    "avg_P_keep = np.mean(event_probs[:, 0])\n",
    "avg_P_lose = np.mean(event_probs[:, 1])\n",
    "avg_P_shot = np.mean(event_probs[:, 2])\n",
    "\n",
    "print(f\"Average Predicted P(Keep Possession): {avg_P_keep:.4f}\")\n",
    "print(f\"Average Predicted P(Lose Possession): {avg_P_lose:.4f}\")\n",
    "print(f\"Average Predicted P(Shot): {avg_P_shot:.4f}\")\n",
    "\n",
    "print(\"\\n--- Goal Prediction Probabilities (xG) ---\")\n",
    "goal_probs = metrics['goal_probs']\n",
    "print(f\"Number of Shots Evaluated: {goal_probs.shape[0]}\")\n",
    "\n",
    "# Average Predicted xG\n",
    "avg_xg = np.mean(goal_probs)\n",
    "print(f\"Average Predicted xG per Shot: {avg_xg:.4f}\")\n",
    "\n",
    "# Total Predicted xG (sum of all probabilities for the shot events)\n",
    "total_xg = np.sum(goal_probs)\n",
    "print(f\"Total Predicted xG for all Shots: {total_xg:.2f}\")\n",
    "\n",
    "# The actual number of goals scored in the test set (True Goals)\n",
    "true_goals = np.sum(metrics['goal_labels'])\n",
    "print(f\"Actual Goals Scored (True Goals): {true_goals:.2f}\")\n",
    "\n",
    "# Print AUC Score (Should be in your metrics dictionary now)\n",
    "print(f\"Goal Prediction AUC-ROC Score: {metrics.get('goal_auc', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the columns that cause the Parquet error\n",
    "LAYER_COLUMNS_TO_DROP = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "def predict_and_save_probabilities(\n",
    "    model, \n",
    "    full_dataset, \n",
    "    original_df: pd.DataFrame, \n",
    "    output_filepath: str,\n",
    "    device: str = 'cpu',\n",
    "    batch_size: int = 1024\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs the model, computes probabilities, assigns them to the original DataFrame,\n",
    "    drops the problematic pitch layer columns, and saves the result as a Parquet file.\n",
    "    \"\"\"\n",
    "    print(f\"Starting prediction on {len(full_dataset)} samples...\")\n",
    "\n",
    "    model.eval() \n",
    "    model.to(device)\n",
    "    pred_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    event_probs_list = []\n",
    "    goal_probs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, _, _ in tqdm(pred_loader, desc=\"Predicting Probabilities\"):\n",
    "            # If using Contextual Model, adjust the unpacking: for X, ctx, _, _ in ...\n",
    "            X = X.to(device)\n",
    "            event_logits, goal_logits = model(X)\n",
    "            \n",
    "            event_probs = F.softmax(event_logits, dim=1) \n",
    "            event_probs_list.append(event_probs.cpu().numpy())\n",
    "            \n",
    "            goal_probs = torch.sigmoid(goal_logits)\n",
    "            goal_probs_list.append(goal_probs.cpu().numpy())\n",
    "\n",
    "    all_event_probs = np.concatenate(event_probs_list, axis=0)\n",
    "    all_goal_probs = np.concatenate(goal_probs_list, axis=0).flatten()\n",
    "\n",
    "    # 1. Assign new columns to the original DataFrame\n",
    "    result_df = original_df.copy()\n",
    "    \n",
    "    result_df.loc[:, 'P_Lose'] = all_event_probs[:, 1]\n",
    "    result_df.loc[:, 'P_Keep'] = all_event_probs[:, 0]\n",
    "    result_df.loc[:, 'P_Shot'] = all_event_probs[:, 2]\n",
    "    result_df.loc[:, 'xG'] = all_goal_probs\n",
    "    \n",
    "    # 2. CRITICAL FIX: Drop the complex object columns before saving!\n",
    "    # These columns contain lists-of-lists (the pitch layers) which Parquet cannot serialize.\n",
    "    columns_to_keep = [col for col in result_df.columns if col not in LAYER_COLUMNS_TO_DROP]\n",
    "    final_df_to_save = result_df[columns_to_keep]\n",
    "\n",
    "    # 3. Save the enriched DataFrame to Parquet\n",
    "    final_df_to_save.to_parquet(output_filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Prediction complete. Data saved to: {output_filepath}\")\n",
    "    return final_df_to_save\n",
    "\n",
    "# Example: Run the function again\n",
    "# final_df_with_probs = predict_and_save_probabilities(...) # using the fixed function\n",
    "\n",
    "# --- Example Usage (Requires your context setup) ---\n",
    "# NOTE: You will need to create the 'full_dataset' object here:\n",
    "full_dataset = PitchDatasetMultiTask(nn_dataset[layer_columns], event_targets, goal_flags) \n",
    "\n",
    "final_df_with_probs = predict_and_save_probabilities(\n",
    "    model=baseline_model,\n",
    "    full_dataset=full_dataset,\n",
    "    original_df=nn_dataset.copy(),\n",
    "    output_filepath='baseline_cnn_predictions.parquet',\n",
    "    device=DEVICE,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db68431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the team name\n",
    "TEAM_NAME = \"Switzerland Women's\"\n",
    "\n",
    "# 2. Filter the DataFrame where Switzerland Women's is either the home or away team\n",
    "switzerland_matches = df_merged[\n",
    "    (df_merged['team'] == TEAM_NAME)]\n",
    "\n",
    "# 3. Get all unique match IDs\n",
    "unique_match_ids = switzerland_matches['match_id'].unique()\n",
    "\n",
    "# 4. Print the result\n",
    "print(unique_match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_possession_sequence(\n",
    "    df_merged: pd.DataFrame, \n",
    "    match_id: int, \n",
    "    possession_id: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the merged DataFrame (raw event data + model predictions)\n",
    "    to return a single, chronologically sorted possession sequence.\n",
    "\n",
    "    Args:\n",
    "        df_merged (pd.DataFrame): The pre-loaded DataFrame containing all merged data.\n",
    "        match_id (int): The match identifier to filter on.\n",
    "        possession_id (int): The possession identifier to filter on.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered and sorted sequence DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Filter for the Specific Possession Sequence\n",
    "    # This filters the full DataFrame down to just the events of interest\n",
    "    df_sequence = df_merged[\n",
    "        (df_merged['match_id'] == match_id) & \n",
    "        (df_merged['possession_id'] == possession_id)\n",
    "    ].copy()\n",
    "    \n",
    "    if df_sequence.empty:\n",
    "        print(f\"⚠️ Warning: Sequence not found for Match ID {match_id}, Possession ID {possession_id}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Sort the sequence chronologically\n",
    "    # Assumes a column like 'event_sequence_in_possession' or a reliable timestamp exists.\n",
    "    # If not, use df_sequence.sort_values(by='timestamp', inplace=True)\n",
    "    if 'event_sequence_in_possession' in df_sequence.columns:\n",
    "        df_sequence.sort_values(by='event_sequence_in_possession', inplace=True)\n",
    "    \n",
    "    # 3. Create a clean chronological index for plotting (X-axis)\n",
    "    df_sequence['seq_index'] = np.arange(len(df_sequence))\n",
    "\n",
    "    print(f\"Sequence extracted with {len(df_sequence)} events, ready for plotting.\")\n",
    "    return df_sequence\n",
    "\n",
    "# --- Next Step: Visualization Function ---\n",
    "\n",
    "def plot_possession_threat_stack(df_sequence: pd.DataFrame, title_suffix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Generates a Stacked Area Chart for the Event Head probabilities (P_outcome).\n",
    "    \"\"\"\n",
    "    if df_sequence.empty:\n",
    "        print(\"Cannot plot: DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    events = df_sequence['seq_index']\n",
    "    \n",
    "    # Ensure probabilities are present and in the correct order for stacking (Lose at the bottom)\n",
    "    # The stackplot inherently calculates the cumulative lines you requested.\n",
    "    y_lose = df_sequence['P_Lose'].values\n",
    "    y_keep = df_sequence['P_Keep'].values\n",
    "    y_shot = df_sequence['P_Shot'].values\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.stackplot(\n",
    "        events,\n",
    "        y_lose,\n",
    "        y_keep,\n",
    "        y_shot,\n",
    "        labels=['P(Lose Possession)', 'P(Keep Possession)', 'P(Shot)'],\n",
    "        colors=['#ff7f0e', '#1f77b4', '#2ca02c'], # Orange, Blue, Green\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    # Add xG values as a secondary line plot for context\n",
    "    ax.plot(events, df_sequence['xG'].values, color='red', linestyle='--', linewidth=2, label='xG (P(Goal) | Shot)')\n",
    "\n",
    "    # --- Add Labels and Title ---\n",
    "    match_id = df_sequence['match_id'].iloc[0]\n",
    "    possession_id = df_sequence['possession_id'].iloc[0]\n",
    "    \n",
    "    ax.set_xlabel(f\"Event Index (Relative to Possession Start) | Total Events: {len(df_sequence)}\", fontsize=12)\n",
    "    ax.set_ylabel(\"Probability / Risk Profile\")\n",
    "    ax.set_title(f\"Threat Model Output (P_outcome) for Match {match_id}, Possession {possession_id} {title_suffix}\", fontsize=14)\n",
    "    \n",
    "    ax.legend(loc='upper right', frameon=True)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Set X-ticks clearly for every 5th event, or just the start/end if the possession is very long\n",
    "    if len(events) < 30:\n",
    "        ax.set_xticks(events[::2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Example Usage (How you would run this in your notebook) ---\n",
    "\n",
    "# 1. ASSUME df_merged IS AVAILABLE\n",
    "# 2. Define your target sequence\n",
    "# TARGET_MATCH = 12345\n",
    "# TARGET_POSSESSION = 50\n",
    "\n",
    "# 3. Get the sequence data\n",
    "# sequence_data = get_possession_sequence(\n",
    "#     df_merged=df_merged,\n",
    "#     match_id=TARGET_MATCH,\n",
    "#     possession_id=TARGET_POSSESSION\n",
    "# )\n",
    "\n",
    "# 4. Plot the results\n",
    "# if not sequence_data.empty:\n",
    "#     plot_possession_threat_stack(sequence_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
