{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accomplished-portable",
   "metadata": {},
   "source": [
    "# Run all Tiny CNNs\n",
    "\n",
    "This file runs all CNNs that are 2d, with and without context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "familiar-northeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo_root: /files/pixlball\n"
     ]
    }
   ],
   "source": [
    "# Load standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "# Set up the root folder to work in any case by seaching for src or .git\n",
    "def find_repo_root(start_path=None, marker_dirs=('src', '.git')):\n",
    "    p = os.path.abspath(start_path or os.getcwd())\n",
    "    while True:\n",
    "        if any(os.path.isdir(os.path.join(p, m)) for m in marker_dirs):\n",
    "            return p\n",
    "        parent = os.path.dirname(p)\n",
    "        if parent == p:\n",
    "            return None\n",
    "        p = parent\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "\n",
    "if repo_root is None:\n",
    "    repo_root = \"/files/pixlball\" # hard coded fallback\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f\"Using repo_root: {repo_root}\")\n",
    "\n",
    "# Import modules\n",
    "import src.data as data\n",
    "import src.model as model\n",
    "import src.train as train\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.evaluate as evaluate\n",
    "import src.utils as utils\n",
    "import src.plotfunctions as plotfunctions\n",
    "import src.losses as losses\n",
    "\n",
    "from src.config import DEVICE \n",
    "\n",
    "\n",
    "# Reloads in cases the files were changed\n",
    "importlib.reload(data)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(plotfunctions)\n",
    "importlib.reload(losses)\n",
    "importlib.reload(config)\n",
    "\n",
    "# Enforce Replicability\n",
    "utils.enforce_replicability(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "similar-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw Data\n",
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "useful-asian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133039 events.\n",
      "counts of each outcome nn_target\n",
      "Keep Possession    635414\n",
      "Lose Possession    245066\n",
      "Shot                38597\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cleans Data and assigns nn targets\n",
    "df_with_targets = data.event_data_loader(data_events)\n",
    "data_events = None # save memory\n",
    "\n",
    "# Adds the ball vector for the kinetic Model\n",
    "df_with_targets = data.add_ball_trajectory_features(df_with_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-ensemble",
   "metadata": {},
   "source": [
    "## Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ideal-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns grid cells to each frame\n",
    "df_360 = data.assign_grid_cells(data_360)\n",
    "data_360 = None # save memory\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-corruption",
   "metadata": {},
   "source": [
    "## Finalize Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sized-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model\n",
    "nn_dataset = data.add_context_cols(nn_dataset)\n",
    "nn_dataset = data.add_target_as_int(nn_dataset)\n",
    "nn_dataset, vector_names = data.add_ball_coordinates(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-recycling",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Event Weights: [0.4530875322204915, 0.7430756467132296, 1.8038368210662787]\n",
      "Goal Pos Weight: 5.0\n",
      "Goal Positive Weight (0/1 ratio): 5.00\n"
     ]
    }
   ],
   "source": [
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "class_weights_event, goal_pos_weight = utils.get_multitask_loss_weights(nn_dataset, DEVICE)\n",
    "\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-jacket",
   "metadata": {},
   "source": [
    "# Prepare Datasets for CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comic-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicable Split: 231 Train Matches, 58 Test Matches\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Use this to prepare your datasets for the final 10-epoch run\n",
    "train_df, val_df = utils.perform_replicable_split(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-season",
   "metadata": {},
   "source": [
    "## Run the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expired-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 643933\n",
      "Total validation samples: 161667\n",
      "Goal Positive Weight (0/1 ratio): 5.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset = dataset.PitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values         # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset = dataset.PitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset)}\")\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 1:  74%|███████▍  | 14940/20123 [01:04<00:22, 229.66it/s, ev_loss=0.1182, loss=0.3494]"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the architecture from the 'arch' module\n",
    "# We name the variable 'baseline_model' to be even clearer\n",
    "import src.model as arch\n",
    "import src.losses as losses\n",
    "from torch.utils.data import DataLoader, Dataset  # <--- Add this line\n",
    "\n",
    "baseline_model = arch.TinyCNN_MultiTask_Threat(\n",
    "    config.GRID_HEIGHT, \n",
    "    config.GRID_WIDTH, \n",
    "    config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# 2. Setup criteria\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# 3. Train using your unified function\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Note: train_multi_task_model should be in your main script or a 'utils' file\n",
    "baseline_model = train.train_multi_task_model(\n",
    "    baseline_model, \n",
    "    train_loader, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.BASELINE_NUM_EPOCHS,\n",
    "    \"Baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the results for the final table\n",
    "final_results = {}\n",
    "\n",
    "# 1. Baseline\n",
    "final_results['Baseline'] = evaluate.evaluate_paper_metrics(baseline_model, validation_dataset, \"Baseline 2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model\n",
    "res = evaluate.get_predictions(baseline_model, validation_dataset)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Baseline CNN\", \"figures/baseline_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Baseline CNN\", \"figures/baseline_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-bobby",
   "metadata": {},
   "source": [
    "## Run the Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_features = ['under_pressure', 'counterpress', 'dribble_nutmeg']\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[context_features]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[context_features]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_context)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. INITIALIZE CONTEXTUAL ARCHITECTURE ---\n",
    "# Calculate how many features are in your context (e.g., 8 for ball vector)\n",
    "num_ctx = len(context_features)\n",
    "\n",
    "context_model = arch.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=num_ctx\n",
    ")\n",
    "\n",
    "# --- 3. SETUP CRITERIA ---\n",
    "# We reuse the same logic as the baseline\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# --- 4. TRAIN USING UNIFIED FUNCTION ---\n",
    "# The train_multi_task_model function you have is already 'unified' \n",
    "# It will detect the 4 items from the loader and pass context to the model automatically.\n",
    "train_loader_ctx = DataLoader(train_dataset_context, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "context_model = train.train_multi_task_model(\n",
    "    context_model, \n",
    "    train_loader_ctx, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    config.CONTEXT_NUM_EPOCHS,\n",
    "    \"Contextual-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Situational Context\n",
    "final_results['Context-Situational'] = evaluate.evaluate_paper_metrics(context_model, validation_dataset_context, \"Situational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model\n",
    "res = evaluate.get_predictions(context_model, validation_dataset_context)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Context CNN\", \"figures/context_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Context CNN\", \"figures/context_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-saudi",
   "metadata": {},
   "source": [
    "## Run the Ball Vector Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. Extract the arrays and Instantiate the Datasets (FIXED)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "## NAME KINETIC DATASET / KINETIC MODEL\n",
    "train_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[vector_names]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[vector_names]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_kinetic)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_kinetic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as arch\n",
    "import src.losses as losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- 1. INITIALIZE KINETIC ARCHITECTURE ---\n",
    "# Identify number of features in your ball vector (e.g., 8)\n",
    "# Ensure 'train_kinetic_dataset' is the one containing your normalized ball vectors\n",
    "num_kinetic_features = 8\n",
    "\n",
    "kinetic_model = arch.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=num_kinetic_features\n",
    ")\n",
    "\n",
    "# Setup all weights / Criteria\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# Load the Data for Training\n",
    "# The train_loader must be built from your kinetic dataset\n",
    "train_loader_kin = DataLoader(train_dataset_kinetic, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Run the unified training function\n",
    "kinetic_model = train.train_multi_task_model(\n",
    "    kinetic_model, \n",
    "    train_loader_kin, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.KINETIC_NUM_EPOCHS,\n",
    "    \"Kinetic-Vector-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Kinetic Model\n",
    "final_results['Context-Kinetic'] = evaluate.evaluate_paper_metrics(kinetic_model, validation_dataset_kinetic, \"Kinetic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get predictions for a specific model (e.g., Kinetic)\n",
    "res = evaluate.get_predictions(kinetic_model, validation_dataset_kinetic)\n",
    "\n",
    "# 2. Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Kinetic CNN\", \"figures/kinetic_event_cm.png\")\n",
    "\n",
    "# 3. Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Kinetic CNN\", \"figures/kinetic_goal_cm.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-internet",
   "metadata": {},
   "source": [
    "# Run 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate the 4D Voxels (Channels, Time, Height, Width)\n",
    "# Lookback 3 = 4 frames total (t, t-1, t-2, t-3)\n",
    "voxels_list = data.generate_temporal_voxels(nn_dataset, lookback=3)\n",
    "\n",
    "# 2. Add as a column\n",
    "nn_dataset['temporal_voxel'] = voxels_list\n",
    "\n",
    "train_df, test_df = utils.perform_replicable_split(nn_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_3d = dataset.VoxelPitchDataset(train_df)\n",
    "test_dataset_3d = dataset.VoxelPitchDataset(test_df)\n",
    "\n",
    "# SMOKE TEST: Check the shape of the first item\n",
    "voxel, event, goal = train_dataset_3d[0]\n",
    "print(f\"Voxel Shape: {voxel.shape}\") # MUST be [3, 4, 12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_weights = [0.69, 1.15, 6.7]\n",
    "class_weights_event = torch.tensor(event_weights, dtype=torch.float32).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "import src.model as arch # issues with imports -> workarround\n",
    "importlib.reload(arch)\n",
    "\n",
    "# --- 1. INITIALIZE 3D ARCHITECTURE ---\n",
    "# This model expects a voxel volume (e.g., 4 frames of spatial grids)\n",
    "voxel_model = arch.Tiny3DCNN_MultiTask(\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# --- 2. SETUP CRITERIA ---\n",
    "# Standardize the loss to ensure a fair comparison with the 2D models\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# --- 3. TRAIN ---\n",
    "# The train_loader must be built from your 3D Voxel dataset\n",
    "# Ensure your 3D dataset returns (voxels, event_targets, goal_targets)\n",
    "train_loader_3d = DataLoader(train_dataset_3d, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# The unified training function will see 3 items (Voxels, Event, Goal)\n",
    "# and treat 'Voxels' as the single 'inputs' argument.\n",
    "voxel_model = train.train_multi_task_model(\n",
    "    voxel_model, \n",
    "    train_loader_3d, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    config.VOXEL_NUM_EPOCHS,\n",
    "    \"3D-Voxel-CNN\",\n",
    "    lr = config.LR_3D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-physics",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate 3D CNN\n",
    "final_results['3D-Voxel'] = evaluate.evaluate_paper_metrics(voxel_model, test_dataset_3d, \"3D CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for a specific model (e.g., Kinetic)\n",
    "res = evaluate.get_predictions(voxel_model, test_dataset_3d)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Voxel CNN\", \"figures/voxel_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Voxel CNN\", \"figures/voxel_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-treaty",
   "metadata": {},
   "source": [
    "# Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "biological-carroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL UTILITY COMPARISON TABLE\n",
      "                     Accuracy  Balanced Acc  Recall_Keep  Recall_Loss  \\\n",
      "Baseline             0.475570      0.603205     0.386121     0.672840   \n",
      "Context-Situational  0.529508      0.612933     0.490005     0.599243   \n",
      "Context-Kinetic      0.538626      0.618588     0.507124     0.585601   \n",
      "3D-Voxel             0.288135      0.336343     0.242944     0.398257   \n",
      "\n",
      "                     Recall_Shot  Goal AUC  \n",
      "Baseline                0.750654  0.628367  \n",
      "Context-Situational     0.749553  0.632880  \n",
      "Context-Kinetic         0.763038  0.626775  \n",
      "3D-Voxel                0.367827  0.505062  \n"
     ]
    }
   ],
   "source": [
    "# Assuming you've run the function for all 4 models as final_results['ModelName']\n",
    "# Example: final_results['Baseline'] = evaluate_paper_metrics(baseline_model, val_dataset, \"Baseline\")\n",
    "\n",
    "# Convert results dictionary to a clean DataFrame\n",
    "df_results = pd.DataFrame(final_results).T\n",
    "\n",
    "# Reorder columns for the paper\n",
    "columns_order = [\"Accuracy\", \"Balanced Acc\", \"Recall_Keep\", \"Recall_Loss\", \"Recall_Shot\", \"Goal AUC\"]\n",
    "df_results = df_results[columns_order]\n",
    "\n",
    "df_results.to_csv(\"model_comparison_table.csv\", index=False)\n",
    "\n",
    "print(\"\\nFINAL UTILITY COMPARISON TABLE\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-oxide",
   "metadata": {},
   "source": [
    "# Plots of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves over the same file, keeping your LaTeX document stable\n",
    "plotfunctions.plot_2d_channels_separated(train_dataset, save_path=\"figures/channel_visualization.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-stick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
