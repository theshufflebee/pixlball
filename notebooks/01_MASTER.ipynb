{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunset-shell",
   "metadata": {},
   "source": [
    "# Run all Tiny CNNs\n",
    "\n",
    "This file runs all CNNs that are 2d, with and without context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "freelance-brazilian",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dd6f2b9ac194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load standard libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_dependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_hard_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dependency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0m_missing_dependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{_dependency}: {_e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_multiarray_umath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inspect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "# Set up the root folder to work in any case by seaching for src or .git\n",
    "def find_repo_root(start_path=None, marker_dirs=('src', '.git')):\n",
    "    p = os.path.abspath(start_path or os.getcwd())\n",
    "    while True:\n",
    "        if any(os.path.isdir(os.path.join(p, m)) for m in marker_dirs):\n",
    "            return p\n",
    "        parent = os.path.dirname(p)\n",
    "        if parent == p:\n",
    "            return None\n",
    "        p = parent\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "\n",
    "if repo_root is None:\n",
    "    repo_root = \"/files/pixlball\" # hard coded fallback\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f\"Using repo_root: {repo_root}\")\n",
    "\n",
    "# Import modules\n",
    "import src.data as data\n",
    "import src.model as model\n",
    "import src.train as train\n",
    "import src.config as config\n",
    "import src.dataset as dataset\n",
    "import src.evaluate as evaluate\n",
    "import src.utils as utils\n",
    "import src.plotfunctions as plotfunctions\n",
    "import src.losses as losses\n",
    "\n",
    "from src.config import DEVICE \n",
    "\n",
    "\n",
    "# Reloads in cases the files were changed\n",
    "importlib.reload(data)\n",
    "importlib.reload(train)\n",
    "importlib.reload(evaluate)\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(plotfunctions)\n",
    "importlib.reload(losses)\n",
    "importlib.reload(config)\n",
    "\n",
    "# Enforce Replicability\n",
    "utils.enforce_replicability(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw Data\n",
    "data_events = pd.read_parquet(os.path.join(repo_root, \"data\", \"events_data.parquet\"), engine=\"fastparquet\")\n",
    "data_360 = pd.read_parquet(os.path.join(repo_root, \"data\", \"sb360_data.parquet\"), engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans Data and assigns nn targets\n",
    "df_with_targets = data.event_data_loader(data_events)\n",
    "data_events = None # save memory\n",
    "\n",
    "# Adds the ball vector for the kinetic Model\n",
    "df_with_targets = data.add_ball_trajectory_features(df_with_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-herald",
   "metadata": {},
   "source": [
    "## Prepare 360 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns grid cells to each frame\n",
    "df_360 = data.assign_grid_cells(data_360)\n",
    "data_360 = None # save memory\n",
    "nn_final = data.aggregate_nn_layers_vectorized(df_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-broad",
   "metadata": {},
   "source": [
    "## Finalize Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the Baseline Dataset\n",
    "nn_dataset = data.prepare_nn_dataset(df_with_targets, nn_final, target_cols=['nn_target', 'goal_flag'], context_cols = True, keep_context_ids = True ) # adjust cols depending on model\n",
    "\n",
    "# Adds the context columns\n",
    "nn_dataset = data.add_context_cols(nn_dataset)\n",
    "\n",
    "# Turns targets into integers\n",
    "nn_dataset = data.add_target_as_int(nn_dataset)\n",
    "\n",
    "# Add the\n",
    "nn_dataset, ball_vector_columns = data.add_ball_coordinates(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-tenant",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Weights\n",
    "class_weights_event, goal_pos_weight = utils.get_multitask_loss_weights(nn_dataset, DEVICE)\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-cancellation",
   "metadata": {},
   "source": [
    "# Prepare Datasets for CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Train / Test Split of the data on matches\n",
    "train_df, val_df = utils.perform_replicable_split(nn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-clone",
   "metadata": {},
   "source": [
    "## Run the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Layer Columns\n",
    "layer_columns = [\"ball_layer\", \"teammates_layer\", \"opponents_layer\"]\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset = dataset.PitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values         # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset = dataset.PitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset)}\")\n",
    "print(f\"Goal Positive Weight (0/1 ratio): {goal_pos_weight.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the architecture from the model module\n",
    "baseline_model = model.TinyCNN_MultiTask_Threat(\n",
    "    config.GRID_HEIGHT, \n",
    "    config.GRID_WIDTH, \n",
    "    config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# Setup criteria / losses\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# Load Data\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "baseline_model = train.train_multi_task_model(\n",
    "    baseline_model, \n",
    "    train_loader, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.BASELINE_NUM_EPOCHS,\n",
    "    \"Baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the results for the final table\n",
    "final_results = {}\n",
    "# Evaluate Baseline CNN\n",
    "final_results['Baseline'] = evaluate.evaluate_paper_metrics(baseline_model, validation_dataset, \"Baseline 2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for a specific model\n",
    "res = evaluate.get_predictions(baseline_model, validation_dataset)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Baseline CNN\", \"figures/baseline_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Baseline CNN\", \"figures/baseline_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-amber",
   "metadata": {},
   "source": [
    "## Run the Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_features = ['under_pressure', 'counterpress', 'dribble_nutmeg']\n",
    "\n",
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[context_features]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_context = dataset.ContextPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[context_features]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_context)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the architecture from the model module\n",
    "# Calculate how many features are in your context (e.g., 8 for ball vector)\n",
    "num_ctx = len(context_features)\n",
    "\n",
    "context_model = model.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=num_ctx\n",
    ")\n",
    "\n",
    "# Setup criteria / losses\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# Load Data\n",
    "train_loader_ctx = DataLoader(train_dataset_context, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "context_model = train.train_multi_task_model(\n",
    "    context_model, \n",
    "    train_loader_ctx, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    config.CONTEXT_NUM_EPOCHS,\n",
    "    \"Contextual-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Context Model\n",
    "final_results['Context-Situational'] = evaluate.evaluate_paper_metrics(context_model, validation_dataset_context, \"Situational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "res = evaluate.get_predictions(context_model, validation_dataset_context)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Context CNN\", \"figures/context_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Context CNN\", \"figures/context_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-alloy",
   "metadata": {},
   "source": [
    "## Run the Ball Vector Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset extraction - Pass only the values in the correct order\n",
    "train_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    train_df[layer_columns],             # This maps to the 1st argument (features)\n",
    "    train_df['nn_target_int'].values,    # This maps to the 2nd argument (events)\n",
    "    train_df['goal_flag'].values,\n",
    "    train_df[ball_vector_columns]        # This maps to the 3rd argument (goals)\n",
    ")\n",
    "\n",
    "# Validation Dataset extraction\n",
    "validation_dataset_kinetic = dataset.ContextBallVectorPitchDatasetMultiTask(\n",
    "    val_df[layer_columns], \n",
    "    val_df['nn_target_int'].values, \n",
    "    val_df['goal_flag'].values,\n",
    "    val_df[ball_vector_columns]  \n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_dataset_kinetic)}\")\n",
    "print(f\"Total validation samples: {len(validation_dataset_kinetic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.model as arch\n",
    "import src.losses as losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize the architecture from the model module\n",
    "# Set number of features in your ball vector (e.g., 8)\n",
    "\n",
    "kinetic_model = arch.TinyCNN_MultiTask_Context_Threat(\n",
    "    grid_height=config.GRID_HEIGHT,\n",
    "    grid_width=config.GRID_WIDTH,\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES,\n",
    "    num_context_features=len(ball_vector_columns)\n",
    ")\n",
    "\n",
    "# Setup criteria / losses\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# # Load Data\n",
    "train_loader_kin = DataLoader(train_dataset_kinetic, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "kinetic_model = train.train_multi_task_model(\n",
    "    kinetic_model, \n",
    "    train_loader_kin, \n",
    "    criterion_ev, \n",
    "    criterion_gl,\n",
    "    config.KINETIC_NUM_EPOCHS,\n",
    "    \"Kinetic-Vector-CNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Kinetic Model\n",
    "final_results['Context-Kinetic'] = evaluate.evaluate_paper_metrics(kinetic_model, validation_dataset_kinetic, \"Kinetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "res = evaluate.get_predictions(kinetic_model, validation_dataset_kinetic)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Kinetic CNN\", \"figures/kinetic_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Kinetic CNN\", \"figures/kinetic_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-identification",
   "metadata": {},
   "source": [
    "# Run 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the 4D Voxels (Channels, Time, Height, Width)\n",
    "# Lookback 3 = 4 frames total (t, t-1, t-2, t-3)\n",
    "voxels_list = data.generate_temporal_voxels(nn_dataset, lookback=3)\n",
    "\n",
    "# Add as a column\n",
    "nn_dataset['temporal_voxel'] = voxels_list\n",
    "\n",
    "train_df, test_df = utils.perform_replicable_split(nn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_3d = dataset.VoxelPitchDataset(train_df)\n",
    "test_dataset_3d = dataset.VoxelPitchDataset(test_df)\n",
    "\n",
    "#Check the shape of the first item\n",
    "#voxel, event, goal = train_dataset_3d[0]\n",
    "#print(f\"Voxel Shape: {voxel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set weights for the 3D Model\n",
    "class_weights_event = torch.tensor(config.VOXEL_WEIGHTS, dtype=torch.float32).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights for each sample in the training set\n",
    "target_list = train_df['nn_target_int'].values\n",
    "class_sample_count = np.array([len(np.where(target_list == t)[0]) for t in np.unique(target_list)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = torch.from_numpy(np.array([weight[t] for t in target_list])).double()\n",
    "\n",
    "# Create the Sampler\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the architecture from the model module\n",
    "voxel_model = model.Tiny3DCNN_MultiTask(\n",
    "    num_event_classes=config.NUM_EVENT_CLASSES\n",
    ")\n",
    "\n",
    "# Setup criteria / losses\n",
    "criterion_ev = losses.FocalLossThreat(alpha=class_weights_event, gamma=2.0)\n",
    "criterion_gl = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([goal_pos_weight]).to(config.DEVICE))\n",
    "\n",
    "# Load Data\n",
    "train_loader_3d = DataLoader(train_dataset_3d, batch_size=config.BATCH_SIZE, sampler=sampler)\n",
    "\n",
    "# Train the model\n",
    "voxel_model = train.train_multi_task_model(\n",
    "    voxel_model, \n",
    "    train_loader_3d, \n",
    "    criterion_ev, \n",
    "    criterion_gl, \n",
    "    config.VOXEL_NUM_EPOCHS,\n",
    "    \"3D-Voxel-CNN\",\n",
    "    lr = config.LR_3D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-hughes",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate 3D CNN\n",
    "final_results['3D-Voxel'] = evaluate.evaluate_paper_metrics(voxel_model, test_dataset_3d, \"3D CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "res = evaluate.get_predictions(voxel_model, test_dataset_3d)\n",
    "\n",
    "# Extract Event Matrix\n",
    "ev_cm = plotfunctions.plot_event_confusion_matrix(res['ev_targets'], res['ev_preds'], \"Voxel CNN\", \"figures/voxel_event_cm.png\")\n",
    "\n",
    "# Extract Goal Matrix\n",
    "gl_cm = plotfunctions.plot_goal_confusion_matrix(res['gl_targets'], res['gl_preds'], \"Voxel CNN\", \"figures/voxel_goal_cm.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-harvard",
   "metadata": {},
   "source": [
    "# Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert the storage of results into a Dataframe\n",
    "df_results = pd.DataFrame(final_results).T\n",
    "\n",
    "# Reorder columns for the paper\n",
    "columns_order = [\"Accuracy\", \"Balanced Acc\", \"Recall_Keep\", \"Recall_Loss\", \"Recall_Shot\", \"Goal AUC\"]\n",
    "df_results = df_results[columns_order]\n",
    "\n",
    "df_results.to_csv(\"model_comparison_table.csv\", index=False)\n",
    "\n",
    "print(\"\\nFINAL UTILITY COMPARISON TABLE\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-addition",
   "metadata": {},
   "source": [
    "# Plots of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the 2d Channel plot for the paper\n",
    "plotfunctions.plot_2d_channels_separated(train_dataset, save_path=\"figures/channel_visualization.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
